{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Scale Image Pixel Data with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (60000, 28, 28) (60000,)\n",
      "Test (10000, 28, 28) (10000,)\n",
      "Train 0 255 33.318421449829934 78.56748998339798\n",
      "Test 0 255 33.791224489795916 79.17246322228644\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images,test_labels) = mnist.load_data()\n",
    "\n",
    "print('Train',train_images.shape, train_labels.shape)\n",
    "print('Test',test_images.shape, test_labels.shape)\n",
    "\n",
    "print('Train', train_images.min(),train_images.max(),train_images.mean(),train_images.std())\n",
    "print('Test', test_images.min(),test_images.max(),test_images.mean(),test_images.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Normalize Images With ImageDataGenerator\n",
    "## - pixel 0 to 255 , 0 to 1 preferred for neural network models.\n",
    "## - scaling data to the range of 0 to 1 is traditionally referred to as normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min=0.000, max=255.000\n",
      "Test min=0.000, max=255.000\n",
      "Batches train=938, test=157\n",
      "Batch shape=(64, 28, 28, 1), min=0.000, max=1.000\n"
     ]
    }
   ],
   "source": [
    "# example of normalizing a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# load dataset\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "# 개수 x width x height\n",
    "# trainX : 60000 x 28 x 28\n",
    "# trainY : 60000,\n",
    "# testX : 10000 x 28 x 28\n",
    "# testY : 10000,\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "# trainX : 60000 x 28 x 28 x 1\n",
    "# testX : 10000 x 28 x 28 x 1\n",
    "\n",
    "# confirm scale of pixels\n",
    "print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\n",
    "print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\n",
    "\n",
    "# create generator (1.0/255.0 = 0.003921568627451)\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Note: there is no need to fit the generator in this case\n",
    "# prepare a iterators to scale images\n",
    "# batch : 이미지 64개씩 그룹으로 묶음(data와 label) 그리고 normalization\n",
    "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
    "# batch : 이미지 64개씩 그룹으로 묶음(test data와 test label) 그리고 normalization\n",
    "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
    "\n",
    "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
    "# confirm the scaling works\n",
    "batchX, batchy = train_iterator.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Center Images With ImageDataGenerator\n",
    "## - Another popular pixel scaling method is to calculate the mean pixel value across the entire training dataset, then subtract it from each image. (=Centering)\n",
    "### - result : distribution of pixel values on zero(=mean pixel value for centered images will be zero)\n",
    "### - It requires that the statistic is calculated on the training dataset prior to scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means train=33.318, test=33.791\n",
      "Data Generator Mean: 33.318\n",
      "(64, 28, 28, 1) 1.4372919\n",
      "(60000, 28, 28, 1) -1.9512918e-05\n"
     ]
    }
   ],
   "source": [
    "# example of centering a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "# report per-image mean\n",
    "print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\n",
    "\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator Mean: %.3f' % datagen.mean)\n",
    "\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape, batchX.mean())\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape, batchX.mean())\n",
    "# mean이 0에 근접함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Standardize Images With ImageDataGenerator\n",
    "## - distribution of the data is Gaussian and shifts the distribution of the data to have a mean of zero and a standard deviation of one.\n",
    "## - data with this distribution is referred to as a standard Gaussian.\n",
    "## - standardization of images is achieved by subtracting the mean pixel value and dividing the result by the standard deviation of the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
      "Data Generator mean=33.318, std=78.567\n",
      "(64, 28, 28, 1) 0.009005004 1.012424\n",
      "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
     ]
    }
   ],
   "source": [
    "# example of standardizing a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "# report pixel means and standard deviations\n",
    "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
