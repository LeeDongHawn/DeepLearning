{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltech101\n",
    "## Label = \"starfish\", \"Faces_easy\",\"grand_piano\",\"watch\",\"ketch\",\"sunflower\"\n",
    "## param : 1,174,358\n",
    "## accuracy : 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "## 그대로 ##\n",
    "#https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # Set to -1 if CPU should be used CPU = -1 , GPU = 0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "elif cpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\n",
    "        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove core ##\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# pip install imutils\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "# <Option 1> You need to import GlobalAveragePooling2D if you want to use GAP model\n",
    "#from keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 수정(핵심) ##\n",
    "class StridedNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes, reg, init=\"he_normal\"):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "\n",
    "\t\t# our first CONV layer will learn a total of 16 filters, each\n",
    "\t\t# Of which are 7x7 -- we'll then apply 2x2 strides to reduce\n",
    "\t\t# the spatial dimensions of the volume\n",
    "\t\t# model.add(Conv2D(16, (7, 7), strides=(2, 2), padding=\"valid\", kernel_initializer=init, kernel_regularizer=reg, input_shape=inputShape))\n",
    "        # 이거 부터 수정 시작하기(conv2D(16,(7,7)))\n",
    "        # maxpooling (2,2)\n",
    "        \n",
    "        # 1. Conv + BatchNormalization + MaxPool + Dropout\n",
    "\t\tmodel.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=inputShape, kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(16, (5, 5), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))        \n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# \t\tmodel.add(Dropout(0.3))\n",
    "        \n",
    "\t\t# here we stack two CONV layers on top of each other where\n",
    "\t\t# each layerswill learn a total of 32 (3x3) filters\n",
    "\t\t#NK: <Option 2> You SHOULD design your own CNN models based on StrideNet (old) model\n",
    "\t\t#NK: Five components of Convolution layer: Conv2D, BatchNormalization, Maxpooling2D, Dropout, Flatten or GlobalAveragePooling2D\n",
    "\t\t#NK: <Option 3> Conv2, same padding, stride (2,2) is essentially same as MaxPooling2D\n",
    "\t\t#NK: You can change following lines to MaxPooling2D\n",
    "        \n",
    "        # 2. [Conv + BatchNormalization]*2 + MaxPool + Dropout\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(32, (5, 5), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "# \t\tmodel.add(Conv2D(32, (5, 5), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "# \t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "# \t\tmodel.add(Conv2D(32, (5, 5), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "# \t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))        \n",
    "# \t\tmodel.add(Dropout(0.3))\n",
    "        \n",
    "\t\t#NK: stack two more CONV layers, keeping the size of each filter\n",
    "\t\t#NK: as 3x3 but increasing to 64 total learned filters\n",
    "\t\t#NK: <Option 3> Conv2, same padding, stride (2,2) is essentially same as MaxPooling2D\n",
    "\t\t#NK: You can change following lines to MaxPooling2D\n",
    "        \n",
    "        # 3. [Conv + BatchNormalization]*2 + MaxPool + Dropout\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (5, 5), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (5, 5), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))        \n",
    "# \t\tmodel.add(Dropout(0.3))\n",
    "\n",
    "\t\t# increase the number of filters again, this time to 128\n",
    "\t\t#NK: <Option 3> Conv2, same padding, stride (2,2) is essentially same as MaxPooling2D\n",
    "\t\t#NK: You can change following lines to MaxPooling2D\n",
    "        \n",
    "        # 4. [Conv + BatchNormalization]*2 + MaxPool + Dropout\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(128, (5, 5), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(128, (5, 5), padding=\"same\", kernel_initializer=init, kernel_regularizer=reg))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))        \n",
    "# \t\tmodel.add(Dropout(0.3))\n",
    "\n",
    "\t\t#NK: <Option 4> You can convert Flatten into GlobalAveragePooling2D, but you have to make sure that you have enough numbers of filters\n",
    "\t\t#NK: If the number of filter is small, performance of GlobalAveragePooling2D is not that good\n",
    "\t\t# fully-connected layer\n",
    "# \t\tmodel.add(Flatten())\n",
    "\n",
    "        # 5. Global Average Pooling\n",
    "\t\tmodel.add(GlobalAveragePooling2D())\n",
    "\t\t#NK: <Option 5> You can add FC (fully connected) layers, up to 2 times\n",
    "\t\t#NK: 3 or more FC layers are not recommended due to long calculation time and increase of parameters\n",
    "\t\tmodel.add(Dense(128, kernel_initializer=init, activation = 'relu'))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\t#NK: <Option 6> You can change ratio of Dropout depending on how large is the image space you need in CNN model\n",
    "# \t\tmodel.add(Dropout(0.3))\n",
    "\n",
    "\t\t#NK: <Caveat> DO NOT CHANGE THIS PART, FINAL LAYER SHOULD BE Dense(#class) with softmax\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes, activation = 'softmax'))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 수정(\"Faces\", \"Leopards\", \"Motorbikes\", \"airplanes\" 제외, 100개 이상 이미지 추천) ##\n",
    "# initialize the set of labels from the CALTECH-101 dataset we are\n",
    "# going to train our network on\n",
    "# LABELS = set([\"Faces\", \"Leopards\", \"Motorbikes\", \"airplanes\"])\n",
    "LABELS = set([\"starfish\", \"Faces_easy\",\"grand_piano\",\"watch\",\"ketch\",\"sunflower\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "## 그대로 ##\n",
    "#imagedir = 'CALTECH101_ObjectCategories'\n",
    "imagefilename = 'D:/파이썬딥러닝/PyImageSearchDeepLearning.vol1/CALTECH101_ObjectCategories.zip'\n",
    "import zipfile\n",
    "print(\"[INFO] loading images...\")\n",
    "#imagePaths = list(paths.list_images(imagedir))\n",
    "zf = zipfile.ZipFile(imagefilename)\n",
    "imagelist = zf.namelist()\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그대로 ##\n",
    "# loop over the image paths\n",
    "#for imagePath in imagePaths:\n",
    "for imagePath in imagelist:\n",
    "\t# extract the class label from the filename\n",
    "\t#print(imagePath.split(os.path.sep), os.path.sep)\n",
    "\t#label = imagePath.split(os.path.sep)[-2]\n",
    "\tlabel = imagePath.split('/')[-2]\n",
    "\n",
    "\t# if the label of the current image is not part of of the labels\n",
    "\t# are interested in, then ignore the image\n",
    "\tif label not in LABELS:\n",
    "\t\tcontinue\n",
    "\n",
    "\t# load the image and resize it to be a fixed 96x96 pixels,\n",
    "\t# ignoring aspect ratio\n",
    "\timagedata = zf.read(imagePath)\n",
    "\t#image = cv2.imread(imagePath)\n",
    "\timage = cv2.imdecode(np.frombuffer(imagedata, np.uint8), 1)\n",
    "\timage = cv2.resize(image, (96, 96))\n",
    "\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그대로 ##\n",
    "# convert the data into a NumPy array, then preprocess it by scaling\n",
    "# all pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그대로 ##\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그대로 ##\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "#NK: <Caveat> DO NOT CHANGE THIS PART, 25% OF DATA WILL BE USED AS TEST SET\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그대로 ##\n",
    "# construct the training image generator for data augmentation\n",
    "#NK: You can do image augmentation further to increase your performance\n",
    "#NK: Check the option of ImageDataGenerator for further processing\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "## epochs, optimizers, regulators 수정가능 ##\n",
    "#NK: You can change # of epochs, optimizers, and regulators\n",
    "#NK: K2 regularizer Strong 0.01 ~ Week 0.0001\n",
    "maxepoch = 150\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=1e-4, decay=1e-4 / maxepoch)\n",
    "model = StridedNet.build(width=96, height=96, depth=3, classes=len(lb.classes_), reg=l2(0.00005))\n",
    "## 그대로 ##\n",
    "#NK: <Caveat> DO NOT CHANGE LOSS FUNCTION, SOFTWARE CLASSFIER ALWAYS USE CATEGORICAL_CROSSTNEROPY\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 96, 96, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 96, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 16)        6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 96, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,174,358\n",
      "Trainable params: 1,172,758\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## 그대로 ##\n",
    "#NK: You have to check dimension of each layers before doing model.fit\n",
    "#NK: Tensorflow will automatically calculate dimensional changes between layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network for 150 epochs...\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 1.4822 - accuracy: 0.5377 - val_loss: 29.3064 - val_accuracy: 0.1509\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 1.0121 - accuracy: 0.7051 - val_loss: 10.1322 - val_accuracy: 0.2981\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.8656 - accuracy: 0.7490 - val_loss: 7.1825 - val_accuracy: 0.1887\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.8429 - accuracy: 0.7545 - val_loss: 5.0829 - val_accuracy: 0.5245\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.7395 - accuracy: 0.8011 - val_loss: 6.4035 - val_accuracy: 0.5094\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.6775 - accuracy: 0.8011 - val_loss: 5.5363 - val_accuracy: 0.4981\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.6634 - accuracy: 0.8080 - val_loss: 7.5010 - val_accuracy: 0.4943\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.6353 - accuracy: 0.8244 - val_loss: 6.6687 - val_accuracy: 0.4943\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.6204 - accuracy: 0.8080 - val_loss: 5.5055 - val_accuracy: 0.4981\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.5375 - accuracy: 0.8542 - val_loss: 5.0492 - val_accuracy: 0.5094\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.5618 - accuracy: 0.8326 - val_loss: 4.9026 - val_accuracy: 0.4943\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 0.4986 - accuracy: 0.8656 - val_loss: 4.7697 - val_accuracy: 0.5170\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.4856 - accuracy: 0.8656 - val_loss: 5.1408 - val_accuracy: 0.5057\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.4664 - accuracy: 0.8656 - val_loss: 5.8843 - val_accuracy: 0.5208\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.5105 - accuracy: 0.8546 - val_loss: 3.0041 - val_accuracy: 0.5358\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.4997 - accuracy: 0.8656 - val_loss: 3.4157 - val_accuracy: 0.5396\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.4614 - accuracy: 0.8724 - val_loss: 2.8216 - val_accuracy: 0.5547\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 1s 125ms/step - loss: 0.4571 - accuracy: 0.8628 - val_loss: 3.0926 - val_accuracy: 0.5698\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.4679 - accuracy: 0.8615 - val_loss: 2.9156 - val_accuracy: 0.5774\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.3980 - accuracy: 0.8848 - val_loss: 2.0424 - val_accuracy: 0.6038\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 1s 125ms/step - loss: 0.4176 - accuracy: 0.8776 - val_loss: 1.9795 - val_accuracy: 0.6075\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.3849 - accuracy: 0.8903 - val_loss: 2.0168 - val_accuracy: 0.6377\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.3926 - accuracy: 0.8889 - val_loss: 1.7606 - val_accuracy: 0.6528\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.3759 - accuracy: 0.9010 - val_loss: 0.7632 - val_accuracy: 0.7509\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.4341 - accuracy: 0.8807 - val_loss: 0.7397 - val_accuracy: 0.7925\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.4250 - accuracy: 0.8916 - val_loss: 1.0783 - val_accuracy: 0.7208\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.3803 - accuracy: 0.8807 - val_loss: 0.7075 - val_accuracy: 0.7925\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.3510 - accuracy: 0.9095 - val_loss: 1.1162 - val_accuracy: 0.7245\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.3543 - accuracy: 0.9095 - val_loss: 0.6126 - val_accuracy: 0.8113\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.3246 - accuracy: 0.9191 - val_loss: 0.7757 - val_accuracy: 0.7623\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.3395 - accuracy: 0.9122 - val_loss: 0.5797 - val_accuracy: 0.8415\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.3470 - accuracy: 0.9191 - val_loss: 0.6202 - val_accuracy: 0.8151\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.3424 - accuracy: 0.9081 - val_loss: 0.7192 - val_accuracy: 0.8226\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 0.3610 - accuracy: 0.8919 - val_loss: 0.6966 - val_accuracy: 0.7887\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.3055 - accuracy: 0.9177 - val_loss: 0.4244 - val_accuracy: 0.8792\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.3120 - accuracy: 0.9163 - val_loss: 0.4069 - val_accuracy: 0.8717\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.3071 - accuracy: 0.9204 - val_loss: 0.4475 - val_accuracy: 0.8642\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.3381 - accuracy: 0.9040 - val_loss: 0.4910 - val_accuracy: 0.8604\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.3137 - accuracy: 0.9328 - val_loss: 0.3069 - val_accuracy: 0.9132\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.3182 - accuracy: 0.9122 - val_loss: 0.3611 - val_accuracy: 0.8906\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2941 - accuracy: 0.9259 - val_loss: 0.3452 - val_accuracy: 0.8868\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.2976 - accuracy: 0.9287 - val_loss: 0.3089 - val_accuracy: 0.9208\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 1s 125ms/step - loss: 0.3125 - accuracy: 0.9108 - val_loss: 0.3177 - val_accuracy: 0.9094\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.3128 - accuracy: 0.9287 - val_loss: 0.3037 - val_accuracy: 0.9208\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.2849 - accuracy: 0.9218 - val_loss: 0.2904 - val_accuracy: 0.9057\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.2859 - accuracy: 0.9163 - val_loss: 0.2887 - val_accuracy: 0.9358\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.2700 - accuracy: 0.9414 - val_loss: 0.2872 - val_accuracy: 0.9170\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2489 - accuracy: 0.9465 - val_loss: 0.2832 - val_accuracy: 0.9245\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2588 - accuracy: 0.9424 - val_loss: 0.2852 - val_accuracy: 0.9170\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.2700 - accuracy: 0.9534 - val_loss: 0.3291 - val_accuracy: 0.9283\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.2733 - accuracy: 0.9369 - val_loss: 0.2798 - val_accuracy: 0.9321\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2522 - accuracy: 0.9424 - val_loss: 0.2810 - val_accuracy: 0.9245\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2432 - accuracy: 0.9451 - val_loss: 0.2843 - val_accuracy: 0.9396\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2448 - accuracy: 0.9424 - val_loss: 0.3381 - val_accuracy: 0.9132\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.2438 - accuracy: 0.9438 - val_loss: 0.2664 - val_accuracy: 0.9321\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.2409 - accuracy: 0.9506 - val_loss: 0.2958 - val_accuracy: 0.9208\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.2498 - accuracy: 0.9369 - val_loss: 0.2785 - val_accuracy: 0.9245\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.2332 - accuracy: 0.9492 - val_loss: 0.2717 - val_accuracy: 0.9208\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 0.2285 - accuracy: 0.9561 - val_loss: 0.2570 - val_accuracy: 0.9396\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.2171 - accuracy: 0.9506 - val_loss: 0.2821 - val_accuracy: 0.9321\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.2005 - accuracy: 0.9698 - val_loss: 0.2310 - val_accuracy: 0.9472\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.95 - 1s 122ms/step - loss: 0.2014 - accuracy: 0.9588 - val_loss: 0.2430 - val_accuracy: 0.9434\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.2135 - accuracy: 0.9561 - val_loss: 0.2142 - val_accuracy: 0.9660\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.1966 - accuracy: 0.9616 - val_loss: 0.2234 - val_accuracy: 0.9547\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.1996 - accuracy: 0.9648 - val_loss: 0.2154 - val_accuracy: 0.9585\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.2171 - accuracy: 0.9479 - val_loss: 0.2522 - val_accuracy: 0.9472\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.2184 - accuracy: 0.9547 - val_loss: 0.2073 - val_accuracy: 0.9547\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.2139 - accuracy: 0.9561 - val_loss: 0.2367 - val_accuracy: 0.9434\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.1915 - accuracy: 0.9648 - val_loss: 0.2105 - val_accuracy: 0.9547\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.1887 - accuracy: 0.9671 - val_loss: 0.2182 - val_accuracy: 0.9509\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.2044 - accuracy: 0.9575 - val_loss: 0.2499 - val_accuracy: 0.9472\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.1871 - accuracy: 0.9684 - val_loss: 0.2198 - val_accuracy: 0.9396\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.1849 - accuracy: 0.9684 - val_loss: 0.2597 - val_accuracy: 0.9358\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.2024 - accuracy: 0.9561 - val_loss: 0.2375 - val_accuracy: 0.9509\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 0.1925 - accuracy: 0.9622 - val_loss: 0.2105 - val_accuracy: 0.9585\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.1696 - accuracy: 0.9726 - val_loss: 0.1882 - val_accuracy: 0.9623\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.1812 - accuracy: 0.9630 - val_loss: 0.1699 - val_accuracy: 0.9736\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.1870 - accuracy: 0.9684 - val_loss: 0.2001 - val_accuracy: 0.9585\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2020 - accuracy: 0.9588 - val_loss: 0.1941 - val_accuracy: 0.9623\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2041 - accuracy: 0.9602 - val_loss: 0.2573 - val_accuracy: 0.9321\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.2280 - accuracy: 0.9479 - val_loss: 0.2107 - val_accuracy: 0.9585\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.1747 - accuracy: 0.9712 - val_loss: 0.2439 - val_accuracy: 0.9358\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.1893 - accuracy: 0.9561 - val_loss: 0.2060 - val_accuracy: 0.9509\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.2008 - accuracy: 0.9544 - val_loss: 0.1960 - val_accuracy: 0.9660\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1757 - accuracy: 0.9739 - val_loss: 0.2404 - val_accuracy: 0.9472\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.1777 - accuracy: 0.9739 - val_loss: 0.2227 - val_accuracy: 0.9434\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.1679 - accuracy: 0.9643 - val_loss: 0.2029 - val_accuracy: 0.9623\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.1599 - accuracy: 0.9753 - val_loss: 0.1886 - val_accuracy: 0.9585\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.1646 - accuracy: 0.9698 - val_loss: 0.1704 - val_accuracy: 0.9736\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.1731 - accuracy: 0.9726 - val_loss: 0.1648 - val_accuracy: 0.9774\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 0.1874 - accuracy: 0.9698 - val_loss: 0.1995 - val_accuracy: 0.9698\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 0.1732 - accuracy: 0.9712 - val_loss: 0.1520 - val_accuracy: 0.9774\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.1629 - accuracy: 0.9698 - val_loss: 0.1985 - val_accuracy: 0.9547\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.1614 - accuracy: 0.9726 - val_loss: 0.1853 - val_accuracy: 0.9585\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.1727 - accuracy: 0.9684 - val_loss: 0.1755 - val_accuracy: 0.9736\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.1692 - accuracy: 0.9698 - val_loss: 0.2036 - val_accuracy: 0.9623\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.1469 - accuracy: 0.9767 - val_loss: 0.1788 - val_accuracy: 0.9623\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.1525 - accuracy: 0.9835 - val_loss: 0.1435 - val_accuracy: 0.9774\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.1579 - accuracy: 0.9781 - val_loss: 0.1624 - val_accuracy: 0.9774\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.1552 - accuracy: 0.9767 - val_loss: 0.1810 - val_accuracy: 0.9774\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.1574 - accuracy: 0.9781 - val_loss: 0.1516 - val_accuracy: 0.9774\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.1653 - accuracy: 0.9671 - val_loss: 0.1783 - val_accuracy: 0.9660\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.1563 - accuracy: 0.9753 - val_loss: 0.1867 - val_accuracy: 0.9623\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.1603 - accuracy: 0.9712 - val_loss: 0.1833 - val_accuracy: 0.9623\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.1701 - accuracy: 0.9698 - val_loss: 0.2261 - val_accuracy: 0.9509\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1495 - accuracy: 0.9767 - val_loss: 0.1906 - val_accuracy: 0.9660\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1496 - accuracy: 0.9794 - val_loss: 0.1595 - val_accuracy: 0.9698\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1463 - accuracy: 0.9753 - val_loss: 0.1730 - val_accuracy: 0.9698\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.1414 - accuracy: 0.9792 - val_loss: 0.1958 - val_accuracy: 0.9509\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1481 - accuracy: 0.9753 - val_loss: 0.1548 - val_accuracy: 0.9774\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.1337 - accuracy: 0.9835 - val_loss: 0.1484 - val_accuracy: 0.9811\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.1329 - accuracy: 0.9890 - val_loss: 0.1457 - val_accuracy: 0.9736\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/12 [==========================>...] - ETA: 0s - loss: 0.1287 - accuracy: 0.9858\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1340 - accuracy: 0.9849 - val_loss: 0.1748 - val_accuracy: 0.9660\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.1234 - accuracy: 0.9877 - val_loss: 0.1702 - val_accuracy: 0.9774\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.1194 - accuracy: 0.9918 - val_loss: 0.1584 - val_accuracy: 0.9774\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1248 - accuracy: 0.9822 - val_loss: 0.1648 - val_accuracy: 0.9736\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1268 - accuracy: 0.9877 - val_loss: 0.1695 - val_accuracy: 0.9736\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1174 - accuracy: 0.9890 - val_loss: 0.1624 - val_accuracy: 0.9774\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.1170 - accuracy: 0.9918 - val_loss: 0.2077 - val_accuracy: 0.9623\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.1389 - accuracy: 0.9890 - val_loss: 0.1876 - val_accuracy: 0.9623\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.1331 - accuracy: 0.9890 - val_loss: 0.1754 - val_accuracy: 0.9623\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1202 - accuracy: 0.9863 - val_loss: 0.1783 - val_accuracy: 0.9660\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.1192 - accuracy: 0.9877 - val_loss: 0.1793 - val_accuracy: 0.9736\n",
      "Epoch 00123: early stopping\n"
     ]
    }
   ],
   "source": [
    "## callback 추가 ##\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 5번 동안 개선되지 않으면 종료(val_loss 를 관찰함)\n",
    "es = EarlyStopping(patience=25, verbose=1)\n",
    "# learning rate scheduler\n",
    "reLR = ReduceLROnPlateau(monitor = 'val_loss', patience=15, verbose=1, factor=0.5)\n",
    "#NK: 25% of test dataset is feeded into CNN model by \"validation_data\"\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(maxepoch))\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=64), validation_data=(testX, testY), steps_per_epoch=len(trainX) // 64, epochs=maxepoch, verbose=1, callbacks=[es,reLR])\n",
    "#batch_size: 32->10 for small GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Faces_easy       1.00      1.00      1.00       109\n",
      " grand_piano       0.96      0.96      0.96        25\n",
      "       ketch       1.00      0.97      0.98        29\n",
      "    starfish       0.86      0.86      0.86        21\n",
      "   sunflower       0.95      0.90      0.93        21\n",
      "       watch       0.97      1.00      0.98        60\n",
      "\n",
      "    accuracy                           0.97       265\n",
      "   macro avg       0.96      0.95      0.95       265\n",
      "weighted avg       0.97      0.97      0.97       265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 그대로 ##\n",
    "#NK: Your performance of CNN model will be evaluated by precision, recall and f1-score\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=64)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 그대로 ##\n",
    "# 만약 early stopping 했다면, maxepoch을 early stopping한 epoch에 맞춰줘야함\n",
    "# plot the training loss and accuracy\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 123), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 123), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 123), H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, 123), H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
