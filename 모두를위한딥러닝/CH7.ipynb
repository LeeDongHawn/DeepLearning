{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.disable_v2_behavior()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.2585707 [[-0.4078342  -0.26444432  0.7523052 ]\n",
      " [ 0.21089911 -0.12519048  0.27151522]\n",
      " [-0.8833627   0.5272891   0.78309405]]\n",
      "1 4.127849 [[-0.38299    -0.26058567  0.72360235]\n",
      " [ 0.37305003 -0.05526839  0.03944223]\n",
      " [-0.7210602   0.60516036  0.5429203 ]]\n",
      "2 3.2018106 [[-0.3582917  -0.3095289   0.74784726]\n",
      " [ 0.5347981  -0.25659144  0.07901728]\n",
      " [-0.5590238   0.41425705  0.5717872 ]]\n",
      "3 2.3207269 [[-0.33462533 -0.31550744  0.73015946]\n",
      " [ 0.69281554 -0.23344757 -0.102144  ]\n",
      " [-0.39975178  0.44230393  0.38446832]]\n",
      "4 1.5843976 [[-0.316382   -0.35526717  0.75167584]\n",
      " [ 0.8198252  -0.38681853 -0.07578266]\n",
      " [-0.26560584  0.2929231   0.39970317]]\n",
      "5 1.2437701 [[-0.3222582  -0.3550045   0.75728935]\n",
      " [ 0.8069935  -0.33202147 -0.11774799]\n",
      " [-0.25591096  0.34493196  0.33799943]]\n",
      "6 1.1913888 [[-0.32745138 -0.36793414  0.7754122 ]\n",
      " [ 0.7953162  -0.33729726 -0.10079492]\n",
      " [-0.24529189  0.33308175  0.33923057]]\n",
      "7 1.1771916 [[-0.33258083 -0.37795603  0.7905635 ]\n",
      " [ 0.78437614 -0.32951894 -0.09763315]\n",
      " [-0.23422779  0.33502012  0.32622808]]\n",
      "8 1.1654277 [[-0.33734432 -0.38866332  0.80603427]\n",
      " [ 0.77540475 -0.32551938 -0.09266131]\n",
      " [-0.22152942  0.3331303   0.31541955]]\n",
      "9 1.1539356 [[-0.34225622 -0.39901683  0.8212997 ]\n",
      " [ 0.765543   -0.32021132 -0.08810758]\n",
      " [-0.20987616  0.33257437  0.30432224]]\n",
      "10 1.1426466 [[-0.3470586  -0.40938357  0.8364688 ]\n",
      " [ 0.756254   -0.31544402 -0.0835859 ]\n",
      " [-0.19790001  0.3315039   0.29341653]]\n",
      "11 1.1315535 [[-0.3518701  -0.4196184   0.8515152 ]\n",
      " [ 0.7468639  -0.3104835  -0.07915631]\n",
      " [-0.18623203  0.33064577  0.28260666]]\n",
      "12 1.120655 [[-0.3566386  -0.42978004  0.8664453 ]\n",
      " [ 0.73767275 -0.3056361  -0.07481252]\n",
      " [-0.17459235  0.3296973   0.27191544]]\n",
      "13 1.1099498 [[-0.3613877  -0.43984193  0.8812563 ]\n",
      " [ 0.7285481  -0.30076998 -0.07055399]\n",
      " [-0.16310552  0.3287882   0.26133773]]\n",
      "14 1.0994374 [[-0.36610743 -0.44981453  0.89594865]\n",
      " [ 0.71954924 -0.29594365 -0.06638148]\n",
      " [-0.15171668  0.3278607   0.25087637]]\n",
      "15 1.0891163 [[-0.37080285 -0.45969203  0.91052157]\n",
      " [ 0.7106497  -0.2911312  -0.06229439]\n",
      " [-0.14045113  0.32694036  0.24053116]]\n",
      "16 1.0789857 [[-0.37547228 -0.469476    0.924975  ]\n",
      " [ 0.7018618  -0.286345   -0.05829268]\n",
      " [-0.12929788  0.3260151   0.23030312]]\n",
      "17 1.0690442 [[-0.3801171  -0.47916478  0.9393086 ]\n",
      " [ 0.69318    -0.2815799  -0.05437597]\n",
      " [-0.11826245  0.32509032  0.22019249]]\n",
      "18 1.0592902 [[-0.38473728 -0.48875827  0.95352226]\n",
      " [ 0.684607   -0.27683902 -0.05054389]\n",
      " [-0.10734271  0.3241633   0.21019979]]\n",
      "19 1.0497221 [[-0.38933355 -0.49825573  0.96761596]\n",
      " [ 0.6761417  -0.27212158 -0.046796  ]\n",
      " [-0.09654004  0.3232352   0.20032518]]\n",
      "20 1.0403385 [[-0.3939062  -0.5076568   0.98158973]\n",
      " [ 0.6677846  -0.26742876 -0.04313174]\n",
      " [-0.08585411  0.32230553  0.19056892]]\n",
      "21 1.0311377 [[-0.39845583 -0.51696116  0.9954437 ]\n",
      " [ 0.6595354  -0.26276082 -0.03955053]\n",
      " [-0.07528537  0.32137465  0.18093106]]\n",
      "22 1.0221174 [[-0.40298283 -0.5261684   1.0091779 ]\n",
      " [ 0.65139437 -0.25811857 -0.03605172]\n",
      " [-0.06483377  0.32044253  0.1714116 ]]\n",
      "23 1.0132761 [[-0.40748775 -0.5352783   1.0227927 ]\n",
      " [ 0.6433613  -0.2535026  -0.0326346 ]\n",
      " [-0.05449953  0.31950945  0.16201045]]\n",
      "24 1.0046115 [[-0.41197106 -0.5442907   1.0362884 ]\n",
      " [ 0.6354361  -0.24891363 -0.0292984 ]\n",
      " [-0.04428266  0.31857562  0.15272741]]\n",
      "25 0.9961214 [[-0.4164333  -0.55320543  1.0496653 ]\n",
      " [ 0.62761873 -0.24435234 -0.0260423 ]\n",
      " [-0.03418323  0.31764135  0.14356224]]\n",
      "26 0.9878039 [[-0.42087495 -0.5620224   1.0629239 ]\n",
      " [ 0.61990905 -0.23981947 -0.02286547]\n",
      " [-0.02420118  0.316707    0.13451457]]\n",
      "27 0.97965646 [[-0.42529655 -0.5707416   1.0760647 ]\n",
      " [ 0.6123069  -0.23531581 -0.01976696]\n",
      " [-0.01433648  0.31577283  0.125584  ]]\n",
      "28 0.97167677 [[-0.42969862 -0.5793631   1.0890883 ]\n",
      " [ 0.604812   -0.23084204 -0.01674586]\n",
      " [-0.00458909  0.31483942  0.11677004]]\n",
      "29 0.9638627 [[-0.43408167 -0.587887    1.1019952 ]\n",
      " [ 0.5974244  -0.22639903 -0.0138012 ]\n",
      " [ 0.00504119  0.3139071   0.10807211]]\n",
      "30 0.95621145 [[-0.43844625 -0.59631336  1.1147861 ]\n",
      " [ 0.5901436  -0.22198752 -0.01093195]\n",
      " [ 0.01455441  0.31297636  0.0994896 ]]\n",
      "31 0.94872075 [[-0.4427929  -0.60464245  1.1274619 ]\n",
      " [ 0.58296955 -0.21760829 -0.0081371 ]\n",
      " [ 0.02395083  0.31204775  0.0910218 ]]\n",
      "32 0.9413879 [[-0.44712213 -0.6128745   1.1400231 ]\n",
      " [ 0.5759019  -0.21326216 -0.00541558]\n",
      " [ 0.03323067  0.31112176  0.08266797]]\n",
      "33 0.93421054 [[-0.45143446 -0.62100977  1.1524707 ]\n",
      " [ 0.56894034 -0.20894985 -0.00276628]\n",
      " [ 0.04239409  0.310199    0.07442732]]\n",
      "34 0.927186 [[-4.5573044e-01 -6.2904859e-01  1.1648055e+00]\n",
      " [ 5.6208462e-01 -2.0467222e-01 -1.8816534e-04]\n",
      " [ 5.1441517e-02  3.0927992e-01  6.6298962e-02]]\n",
      "35 0.92031157 [[-0.4600106  -0.6369913   1.1770284 ]\n",
      " [ 0.55533427 -0.20042993  0.00231992]\n",
      " [ 0.06037316  0.30836523  0.05828201]]\n",
      "36 0.91358465 [[-0.46427542 -0.6448384   1.1891403 ]\n",
      " [ 0.548689   -0.19622387  0.00475909]\n",
      " [ 0.06918947  0.30745542  0.0503755 ]]\n",
      "37 0.90700257 [[-0.46852547 -0.6525902   1.2011422 ]\n",
      " [ 0.5421485  -0.19205469  0.00713049]\n",
      " [ 0.07789078  0.30655116  0.04257845]]\n",
      "38 0.90056276 [[-0.47276124 -0.66024727  1.213035  ]\n",
      " [ 0.5357121  -0.18792313  0.00943526]\n",
      " [ 0.08647754  0.305653    0.03488984]]\n",
      "39 0.89426243 [[-0.47698322 -0.66781014  1.2248198 ]\n",
      " [ 0.5293796  -0.18382993  0.01167455]\n",
      " [ 0.09495021  0.30476156  0.0273086 ]]\n",
      "40 0.88809896 [[-0.48119193 -0.6752793   1.2364976 ]\n",
      " [ 0.52315044 -0.17977573  0.01384949]\n",
      " [ 0.1033093   0.30387747  0.01983361]]\n",
      "41 0.88206977 [[-0.48538786 -0.6826554   1.2480696 ]\n",
      " [ 0.51702416 -0.17576122  0.01596127]\n",
      " [ 0.11155531  0.30300128  0.01246378]]\n",
      "42 0.87617195 [[-0.48957148 -0.689939    1.2595369 ]\n",
      " [ 0.5110002  -0.17178701  0.01801101]\n",
      " [ 0.11968881  0.30213365  0.00519791]]\n",
      "43 0.87040293 [[-0.49374324 -0.6971308   1.2709004 ]\n",
      " [ 0.5050781  -0.16785368  0.01999987]\n",
      " [ 0.12771039  0.30127513 -0.00196513]]\n",
      "44 0.8647602 [[-0.49790365 -0.7042314   1.2821614 ]\n",
      " [ 0.49925715 -0.16396187  0.021929  ]\n",
      " [ 0.13562068  0.30042627 -0.00902656]]\n",
      "45 0.85924095 [[-0.50205314 -0.7112415   1.2933209 ]\n",
      " [ 0.49353686 -0.16011208  0.02379952]\n",
      " [ 0.14342037  0.29958764 -0.01598762]]\n",
      "46 0.8538426 [[-0.50619215 -0.71816176  1.3043802 ]\n",
      " [ 0.48791656 -0.15630482  0.02561255]\n",
      " [ 0.15111011  0.29875982 -0.02284953]]\n",
      "47 0.8485626 [[-0.5103211  -0.724993    1.3153404 ]\n",
      " [ 0.48239568 -0.15254061  0.02736923]\n",
      " [ 0.15869069  0.29794326 -0.02961353]]\n",
      "48 0.84339815 [[-0.5144404  -0.7317359   1.3262026 ]\n",
      " [ 0.47697344 -0.14881982  0.02907067]\n",
      " [ 0.16616277  0.29713854 -0.0362809 ]]\n",
      "49 0.83834696 [[-0.5185505  -0.7383913   1.3369681 ]\n",
      " [ 0.4716493  -0.14514294  0.03071797]\n",
      " [ 0.17352724  0.2963461  -0.0428529 ]]\n",
      "50 0.8334063 [[-0.52265173 -0.7449599   1.3476379 ]\n",
      " [ 0.46642235 -0.14151025  0.03231221]\n",
      " [ 0.1807848   0.29556644 -0.04933081]]\n",
      "51 0.8285737 [[-0.5267445  -0.75144255  1.3582133 ]\n",
      " [ 0.46129203 -0.1379222   0.03385447]\n",
      " [ 0.18793643  0.29479995 -0.05571593]]\n",
      "52 0.8238467 [[-0.5308292  -0.75784004  1.3686955 ]\n",
      " [ 0.45625746 -0.13437895  0.03534582]\n",
      " [ 0.19498286  0.29404712 -0.06200954]]\n",
      "53 0.8192229 [[-0.53490615 -0.76415324  1.3790857 ]\n",
      " [ 0.4513179  -0.13088089  0.0367873 ]\n",
      " [ 0.20192508  0.29330826 -0.06821293]]\n",
      "54 0.81469965 [[-0.5389757  -0.77038294  1.389385  ]\n",
      " [ 0.44647253 -0.12742814  0.03817995]\n",
      " [ 0.20876399  0.29258382 -0.07432742]]\n",
      "55 0.8102748 [[-0.5430382  -0.77653     1.3995945 ]\n",
      " [ 0.4417205  -0.12402096  0.03952479]\n",
      " [ 0.21550056  0.2918741  -0.0803543 ]]\n",
      "56 0.805946 [[-0.5470939  -0.7825953   1.4097155 ]\n",
      " [ 0.43706095 -0.12065947  0.04082284]\n",
      " [ 0.22213577  0.29117945 -0.08629484]]\n",
      "57 0.8017107 [[-0.5511432  -0.78857964  1.4197491 ]\n",
      " [ 0.43249303 -0.1173438   0.04207509]\n",
      " [ 0.22867063  0.29050013 -0.09215037]]\n",
      "58 0.79756683 [[-0.5551864  -0.79448396  1.4296966 ]\n",
      " [ 0.4280158  -0.114074    0.04328252]\n",
      " [ 0.23510611  0.2898364  -0.09792215]]\n",
      "59 0.793512 [[-0.55922365 -0.80030906  1.439559  ]\n",
      " [ 0.4236284  -0.11085013  0.04444607]\n",
      " [ 0.24144334  0.28918853 -0.1036115 ]]\n",
      "60 0.78954405 [[-0.56325525 -0.8060559   1.4493374 ]\n",
      " [ 0.41932982 -0.10767218  0.04556669]\n",
      " [ 0.24768333  0.28855672 -0.10921969]]\n",
      "61 0.78566074 [[-0.5672815  -0.8117253   1.459033  ]\n",
      " [ 0.41511914 -0.10454013  0.04664533]\n",
      " [ 0.2538272   0.28794116 -0.11474798]]\n",
      "62 0.78186 [[-0.5713026  -0.8173182   1.468647  ]\n",
      " [ 0.4109954  -0.10145395  0.0476829 ]\n",
      " [ 0.25987607  0.28734198 -0.12019765]]\n",
      "63 0.7781398 [[-0.57531875 -0.82283545  1.4781804 ]\n",
      " [ 0.40695754 -0.09841347  0.04868029]\n",
      " [ 0.265831    0.28675938 -0.12556995]]\n",
      "64 0.774498 [[-0.5793302  -0.82827795  1.4876344 ]\n",
      " [ 0.40300462 -0.09541865  0.04963841]\n",
      " [ 0.2716932   0.28619337 -0.13086616]]\n",
      "65 0.7709325 [[-0.5833371  -0.83364666  1.49701   ]\n",
      " [ 0.39913556 -0.09246929  0.05055809]\n",
      " [ 0.27746382  0.28564408 -0.1360875 ]]\n",
      "66 0.76744145 [[-0.58733976 -0.8389424   1.5063083 ]\n",
      " [ 0.39534932 -0.08956518  0.05144021]\n",
      " [ 0.283144    0.2851116  -0.14123523]]\n",
      "67 0.76402295 [[-0.5913382  -0.8441661   1.5155305 ]\n",
      " [ 0.3916449  -0.08670613  0.0522856 ]\n",
      " [ 0.28873497  0.28459597 -0.14631054]]\n",
      "68 0.7606749 [[-0.5953327  -0.8493186   1.5246775 ]\n",
      " [ 0.3880212  -0.08389192  0.0530951 ]\n",
      " [ 0.2942379   0.28409716 -0.15131466]]\n",
      "69 0.75739574 [[-0.5993233  -0.8544009   1.5337504 ]\n",
      " [ 0.38447714 -0.08112225  0.05386951]\n",
      " [ 0.29965404  0.28361517 -0.1562488 ]]\n",
      "70 0.7541833 [[-0.60331017 -0.85941374  1.5427502 ]\n",
      " [ 0.38101158 -0.0783968   0.05460962]\n",
      " [ 0.3049845   0.28315002 -0.16111413]]\n",
      "71 0.7510361 [[-0.6072935  -0.8643582   1.551678  ]\n",
      " [ 0.3776235  -0.07571533  0.05531622]\n",
      " [ 0.31023067  0.28270158 -0.16591184]]\n",
      "72 0.7479522 [[-0.61127335 -0.869235    1.5605346 ]\n",
      " [ 0.37431177 -0.07307743  0.05599007]\n",
      " [ 0.3153937   0.28226984 -0.17064309]]\n",
      "73 0.74493 [[-0.6152499  -0.8740451   1.5693213 ]\n",
      " [ 0.3710752  -0.07048272  0.05663194]\n",
      " [ 0.32047474  0.28185472 -0.17530903]]\n",
      "74 0.741968 [[-0.6192232  -0.8787893   1.5780388 ]\n",
      " [ 0.36791283 -0.06793091  0.05724254]\n",
      " [ 0.32547522  0.28145605 -0.17991081]]\n",
      "75 0.73906434 [[-0.6231933  -0.88346857  1.5866882 ]\n",
      " [ 0.36482334 -0.06542149  0.0578226 ]\n",
      " [ 0.3303962   0.2810738  -0.18444955]]\n",
      "76 0.73621756 [[-0.6271604  -0.88808376  1.5952704 ]\n",
      " [ 0.36180574 -0.06295414  0.05837286]\n",
      " [ 0.3352391   0.28070772 -0.18892637]]\n",
      "77 0.7334261 [[-0.63112444 -0.8926357   1.6037863 ]\n",
      " [ 0.3588588  -0.06052833  0.05889399]\n",
      " [ 0.34000507  0.28035775 -0.19334237]]\n",
      "78 0.73068845 [[-0.6350856  -0.89712524  1.612237  ]\n",
      " [ 0.35598144 -0.05814366  0.0593867 ]\n",
      " [ 0.3446954   0.2800237  -0.19769862]]\n",
      "79 0.72800314 [[-0.6390438  -0.9015533   1.6206232 ]\n",
      " [ 0.35317248 -0.05579966  0.05985166]\n",
      " [ 0.3493113   0.27970535 -0.20199619]]\n",
      "80 0.725369 [[-0.64299923 -0.9059206   1.628946  ]\n",
      " [ 0.35043082 -0.05349583  0.06028951]\n",
      " [ 0.35385406  0.27940255 -0.20623615]]\n",
      "81 0.72278416 [[-0.64695185 -0.91022813  1.6372061 ]\n",
      " [ 0.34775525 -0.05123166  0.06070092]\n",
      " [ 0.35832492  0.2791151  -0.21041954]]\n",
      "82 0.7202476 [[-0.65090173 -0.91447663  1.6454045 ]\n",
      " [ 0.3451447  -0.0490067   0.06108652]\n",
      " [ 0.3627251   0.27884275 -0.21454738]]\n",
      "83 0.71775806 [[-0.65484893 -0.9186669   1.6535419 ]\n",
      " [ 0.342598   -0.04682039  0.06144692]\n",
      " [ 0.3670559   0.27858528 -0.21862072]]\n",
      "84 0.71531403 [[-0.65879345 -0.92279977  1.6616193 ]\n",
      " [ 0.340114   -0.04467222  0.06178275]\n",
      " [ 0.37131846  0.2783425  -0.2226405 ]]\n",
      "85 0.71291435 [[-0.6627353  -0.92687607  1.6696374 ]\n",
      " [ 0.33769163 -0.04256171  0.06209461]\n",
      " [ 0.37551412  0.27811405 -0.22660775]]\n",
      "86 0.71055806 [[-0.66667444 -0.93089664  1.6775972 ]\n",
      " [ 0.33532965 -0.0404882   0.06238309]\n",
      " [ 0.37964398  0.27789986 -0.23052342]]\n",
      "87 0.7082436 [[-0.67061096 -0.9348622   1.6854993 ]\n",
      " [ 0.33302706 -0.03845129  0.06264877]\n",
      " [ 0.38370937  0.27769953 -0.23438847]]\n",
      "88 0.70597017 [[-0.6745448  -0.9387736   1.6933446 ]\n",
      " [ 0.33078265 -0.03645033  0.0628922 ]\n",
      " [ 0.3877114   0.27751285 -0.23820385]]\n",
      "89 0.7037364 [[-0.67847604 -0.94263154  1.7011337 ]\n",
      " [ 0.3285954  -0.03448483  0.06311396]\n",
      " [ 0.39165136  0.27733955 -0.24197048]]\n",
      "90 0.7015414 [[-0.68240464 -0.9464369   1.7088677 ]\n",
      " [ 0.32646412 -0.03255417  0.06331461]\n",
      " [ 0.3955303   0.27717936 -0.24568924]]\n",
      "91 0.69938403 [[-0.68633056 -0.9501903   1.716547  ]\n",
      " [ 0.32438776 -0.03065785  0.06349465]\n",
      " [ 0.3993495   0.277032   -0.24936107]]\n",
      "92 0.6972633 [[-0.6902538  -0.9538926   1.7241726 ]\n",
      " [ 0.3223652  -0.02879528  0.06365463]\n",
      " [ 0.4031101   0.27689716 -0.25298685]]\n",
      "93 0.6951782 [[-0.69417435 -0.9575445   1.731745  ]\n",
      " [ 0.3203954  -0.02696592  0.06379505]\n",
      " [ 0.40681323  0.2767746  -0.25656742]]\n",
      "94 0.6931279 [[-0.6980922  -0.9611467   1.7392651 ]\n",
      " [ 0.3184773  -0.02516917  0.06391641]\n",
      " [ 0.41046005  0.27666402 -0.26010367]]\n",
      "95 0.6911112 [[-0.70200735 -0.9647      1.7467335 ]\n",
      " [ 0.3166098  -0.0234045   0.06401924]\n",
      " [ 0.41405165  0.27656516 -0.26359642]]\n",
      "96 0.6891275 [[-0.70591974 -0.96820503  1.754151  ]\n",
      " [ 0.31479195 -0.02167137  0.064104  ]\n",
      " [ 0.41758922  0.2764777  -0.26704648]]\n",
      "97 0.68717575 [[-0.7098294  -0.9716626   1.7615181 ]\n",
      " [ 0.31302258 -0.01996918  0.06417118]\n",
      " [ 0.42107376  0.27640137 -0.2704547 ]]\n",
      "98 0.68525517 [[-0.71373624 -0.9750733   1.7688357 ]\n",
      " [ 0.31130075 -0.0182974   0.06422124]\n",
      " [ 0.42450643  0.27633587 -0.27382186]]\n",
      "99 0.6833649 [[-0.7176402  -0.97843784  1.7761042 ]\n",
      " [ 0.30962545 -0.01665548  0.06425463]\n",
      " [ 0.4278883   0.27628088 -0.27714875]]\n",
      "100 0.68150425 [[-0.72154135 -0.9817569   1.7833245 ]\n",
      " [ 0.30799562 -0.01504282  0.06427182]\n",
      " [ 0.43122035  0.2762362  -0.28043613]]\n",
      "101 0.6796723 [[-0.7254396  -0.9850312   1.7904971 ]\n",
      " [ 0.30641034 -0.01345897  0.06427324]\n",
      " [ 0.43450373  0.27620146 -0.28368476]]\n",
      "102 0.6778684 [[-0.72933495 -0.98826134  1.7976226 ]\n",
      " [ 0.30486858 -0.0119033   0.06425931]\n",
      " [ 0.43773937  0.27617642 -0.2868954 ]]\n",
      "103 0.6760918 [[-0.7332273  -0.991448    1.8047016 ]\n",
      " [ 0.30336946 -0.01037533  0.06423046]\n",
      " [ 0.44092837  0.27616078 -0.29006875]]\n",
      "104 0.6743418 [[-0.73711663 -0.9945918   1.8117347 ]\n",
      " [ 0.30191195 -0.00887449  0.06418712]\n",
      " [ 0.44407165  0.27615428 -0.29320556]]\n",
      "105 0.6726177 [[-0.7410029  -0.99769336  1.8187226 ]\n",
      " [ 0.30049515 -0.00740027  0.0641297 ]\n",
      " [ 0.44717023  0.27615663 -0.2963065 ]]\n",
      "106 0.6709188 [[-0.74488616 -1.0007534   1.8256658 ]\n",
      " [ 0.29911816 -0.00595215  0.06405855]\n",
      " [ 0.45022509  0.27616757 -0.2993723 ]]\n",
      "107 0.6692445 [[-0.7487663  -1.0037724   1.832565  ]\n",
      " [ 0.29778007 -0.00452961  0.0639741 ]\n",
      " [ 0.45323715  0.27618682 -0.3024036 ]]\n",
      "108 0.6675943 [[-0.7526432  -1.0067511   1.8394206 ]\n",
      " [ 0.29647997 -0.00313216  0.06387673]\n",
      " [ 0.45620736  0.27621406 -0.30540106]]\n",
      "109 0.66596735 [[-7.5651699e-01 -1.0096899e+00  1.8462331e+00]\n",
      " [ 2.9521698e-01 -1.7592303e-03  6.3766800e-02]\n",
      " [ 4.5913664e-01  2.7624914e-01 -3.0836540e-01]]\n",
      "110 0.66436327 [[-7.6038754e-01 -1.0125896e+00  1.8530033e+00]\n",
      " [ 2.9399025e-01 -4.1041139e-04  6.3644692e-02]\n",
      " [ 4.6202588e-01  2.7629167e-01 -3.1129721e-01]]\n",
      "111 0.6627815 [[-7.6425481e-01 -1.0154506e+00  1.8597316e+00]\n",
      " [ 2.9279894e-01  9.1486028e-04  6.3510746e-02]\n",
      " [ 4.6487600e-01  2.7634150e-01 -3.1419712e-01]]\n",
      "112 0.66122127 [[-0.76811874 -1.0182736   1.8664185 ]\n",
      " [ 0.29164222  0.00221701  0.06336533]\n",
      " [ 0.46768785  0.27639827 -0.31706575]]\n",
      "113 0.65968233 [[-0.77197933 -1.021059    1.8730645 ]\n",
      " [ 0.2905192   0.00349658  0.06320877]\n",
      " [ 0.47046223  0.27646184 -0.31990373]]\n",
      "114 0.658164 [[-0.77583647 -1.0238076   1.8796703 ]\n",
      " [ 0.28942922  0.00475393  0.06304143]\n",
      " [ 0.4732001   0.27653185 -0.32271162]]\n",
      "115 0.6566658 [[-0.7796902  -1.0265198   1.8862362 ]\n",
      " [ 0.2883713   0.00598969  0.0628636 ]\n",
      " [ 0.47590217  0.2766082  -0.32549003]]\n",
      "116 0.65518725 [[-0.7835404  -1.0291961   1.8927628 ]\n",
      " [ 0.28734484  0.0072041   0.06267562]\n",
      " [ 0.4785694   0.27669048 -0.32823953]]\n",
      "117 0.6537279 [[-0.7873872  -1.0318371   1.8992505 ]\n",
      " [ 0.2863489   0.00839784  0.0624778 ]\n",
      " [ 0.48120236  0.27677864 -0.3309607 ]]\n",
      "118 0.6522872 [[-0.7912304  -1.0344433   1.9056998 ]\n",
      " [ 0.28538293  0.00957114  0.06227047]\n",
      " [ 0.48380205  0.27687228 -0.33365402]]\n",
      "119 0.65086496 [[-0.79506993 -1.0370151   1.9121113 ]\n",
      " [ 0.28444606  0.01072458  0.0620539 ]\n",
      " [ 0.4863691   0.2769713  -0.33632007]]\n",
      "120 0.6494603 [[-0.79890585 -1.039553    1.9184853 ]\n",
      " [ 0.28353763  0.01185851  0.0618284 ]\n",
      " [ 0.4889043   0.27707544 -0.3389594 ]]\n",
      "121 0.64807343 [[-0.80273813 -1.0420578   1.9248222 ]\n",
      " [ 0.2826569   0.01297336  0.06159427]\n",
      " [ 0.49140838  0.27718446 -0.3415725 ]]\n",
      "122 0.6467035 [[-0.8065667  -1.0445296   1.9311227 ]\n",
      " [ 0.2818032   0.01406956  0.06135179]\n",
      " [ 0.49388203  0.27729818 -0.34415984]]\n",
      "123 0.6453501 [[-0.81039155 -1.046969    1.937387  ]\n",
      " [ 0.28097585  0.01514749  0.06110121]\n",
      " [ 0.496326    0.27741638 -0.346722  ]]\n",
      "124 0.64401305 [[-0.81421256 -1.0493766   1.9436157 ]\n",
      " [ 0.28017417  0.01620754  0.06084282]\n",
      " [ 0.49874094  0.27753884 -0.3492594 ]]\n",
      "125 0.64269197 [[-0.81802976 -1.0517528   1.9498091 ]\n",
      " [ 0.27939755  0.01725011  0.06057686]\n",
      " [ 0.5011276   0.27766538 -0.35177258]]\n",
      "126 0.6413864 [[-0.82184315 -1.054098    1.9559677 ]\n",
      " [ 0.27864528  0.01827562  0.06030361]\n",
      " [ 0.5034865   0.27779585 -0.35426196]]\n",
      "127 0.64009607 [[-0.8256526  -1.0564127   1.9620918 ]\n",
      " [ 0.27791685  0.01928436  0.06002331]\n",
      " [ 0.5058184   0.27793    -0.35672802]]\n",
      "128 0.63882065 [[-0.8294582  -1.0586972   1.968182  ]\n",
      " [ 0.27721152  0.02027678  0.05973621]\n",
      " [ 0.5081239   0.2780677  -0.3591712 ]]\n",
      "129 0.6375598 [[-0.83325976 -1.0609522   1.9742385 ]\n",
      " [ 0.27652884  0.02125311  0.05944258]\n",
      " [ 0.51040363  0.27820867 -0.36159194]]\n",
      "130 0.6363131 [[-0.8370574  -1.0631778   1.9802618 ]\n",
      " [ 0.27586806  0.02221388  0.0591426 ]\n",
      " [ 0.5126582   0.2783529  -0.36399066]]\n",
      "131 0.63508034 [[-0.840851   -1.0653746   1.9862523 ]\n",
      " [ 0.27522874  0.02315928  0.05883653]\n",
      " [ 0.51488817  0.27850005 -0.36636782]]\n",
      "132 0.6338612 [[-0.8446406  -1.067543    1.9922103 ]\n",
      " [ 0.27461022  0.02408972  0.0585246 ]\n",
      " [ 0.5170941   0.27865008 -0.36872378]]\n",
      "133 0.6326555 [[-0.8484261  -1.0696834   1.9981362 ]\n",
      " [ 0.2740121   0.02500547  0.05820701]\n",
      " [ 0.5192766   0.27880272 -0.37105897]]\n",
      "134 0.63146275 [[-0.85220754 -1.0717963   2.0040305 ]\n",
      " [ 0.27343366  0.02590694  0.05788396]\n",
      " [ 0.5214362   0.27895796 -0.3733738 ]]\n",
      "135 0.6302829 [[-0.8559848  -1.0738819   2.0098934 ]\n",
      " [ 0.27287453  0.02679436  0.05755568]\n",
      " [ 0.5235735   0.27911556 -0.37566867]]\n",
      "136 0.62911546 [[-0.85975796 -1.0759406   2.0157254 ]\n",
      " [ 0.27233413  0.02766808  0.05722238]\n",
      " [ 0.525689    0.27927536 -0.37794393]]\n",
      "137 0.6279603 [[-0.86352694 -1.0779729   2.0215266 ]\n",
      " [ 0.27181193  0.02852841  0.05688426]\n",
      " [ 0.52778316  0.27943724 -0.38019997]]\n",
      "138 0.6268172 [[-0.8672917  -1.0799791   2.0272975 ]\n",
      " [ 0.27130756  0.02937558  0.05654149]\n",
      " [ 0.52985656  0.279601   -0.38243714]]\n",
      "139 0.6256858 [[-0.8710522  -1.0819595   2.0330386 ]\n",
      " [ 0.2708204   0.03020997  0.05619426]\n",
      " [ 0.53190964  0.27976662 -0.3846558 ]]\n",
      "140 0.6245661 [[-0.8748085  -1.0839146   2.03875   ]\n",
      " [ 0.27035007  0.03103178  0.05584277]\n",
      " [ 0.5339429   0.27993387 -0.38685632]]\n",
      "141 0.62345755 [[-0.8785605  -1.0858448   2.044432  ]\n",
      " [ 0.2698961   0.03184134  0.05548718]\n",
      " [ 0.53595674  0.28010267 -0.38903904]]\n",
      "142 0.6223602 [[-0.8823082  -1.0877502   2.050085  ]\n",
      " [ 0.26945806  0.03263887  0.05512769]\n",
      " [ 0.53795177  0.28027287 -0.39120427]]\n",
      "143 0.62127364 [[-0.8860516  -1.0896313   2.0557096 ]\n",
      " [ 0.26903546  0.03342472  0.05476445]\n",
      " [ 0.5399283   0.2804444  -0.39335236]]\n",
      "144 0.6201978 [[-0.88979065 -1.0914884   2.0613058 ]\n",
      " [ 0.26862797  0.03419903  0.05439764]\n",
      " [ 0.54188687  0.2806171  -0.3954836 ]]\n",
      "145 0.6191323 [[-0.8935254  -1.0933218   2.066874  ]\n",
      " [ 0.2682351   0.03496213  0.05402741]\n",
      " [ 0.54382783  0.28079087 -0.39759836]]\n",
      "146 0.61807716 [[-0.8972558  -1.0951319   2.0724144 ]\n",
      " [ 0.2678565   0.03571421  0.05365392]\n",
      " [ 0.5457517   0.28096557 -0.39969692]]\n",
      "147 0.617032 [[-0.9009818  -1.096919    2.0779274 ]\n",
      " [ 0.2674917   0.0364556   0.05327734]\n",
      " [ 0.54765874  0.28114116 -0.4017796 ]]\n",
      "148 0.6159967 [[-0.9047034  -1.0986832   2.0834134 ]\n",
      " [ 0.26714042  0.03718641  0.05289782]\n",
      " [ 0.5495495   0.28131744 -0.40384665]]\n",
      "149 0.61497116 [[-0.90842056 -1.1004251   2.0888724 ]\n",
      " [ 0.2668022   0.03790698  0.05251548]\n",
      " [ 0.55142426  0.28149444 -0.4058984 ]]\n",
      "150 0.613955 [[-0.91213334 -1.102145    2.094305  ]\n",
      " [ 0.26647672  0.03861745  0.05213049]\n",
      " [ 0.55328345  0.28167194 -0.40793508]]\n",
      "151 0.61294836 [[-0.91584164 -1.103843    2.0997114 ]\n",
      " [ 0.2661636   0.03931811  0.05174297]\n",
      " [ 0.55512744  0.28184995 -0.40995705]]\n",
      "152 0.6119507 [[-0.91954553 -1.1055195   2.1050918 ]\n",
      " [ 0.2658625   0.0400091   0.05135307]\n",
      " [ 0.5569565   0.2820283  -0.4119645 ]]\n",
      "153 0.61096215 [[-0.92324495 -1.1071749   2.1104465 ]\n",
      " [ 0.26557308  0.04069069  0.05096089]\n",
      " [ 0.55877113  0.28220695 -0.41395777]]\n",
      "154 0.6099824 [[-0.9269399  -1.1088092   2.1157758 ]\n",
      " [ 0.26529503  0.04136303  0.0505666 ]\n",
      " [ 0.5605716   0.2823858  -0.41593707]]\n",
      "155 0.60901123 [[-0.9306304  -1.110423    2.12108   ]\n",
      " [ 0.26502803  0.04202636  0.05017029]\n",
      " [ 0.56235826  0.28256476 -0.41790268]]\n",
      "156 0.6080487 [[-0.93431634 -1.1120162   2.1263592 ]\n",
      " [ 0.26477173  0.04268087  0.0497721 ]\n",
      " [ 0.5641314   0.2827438  -0.41985485]]\n",
      "157 0.6070944 [[-0.9379978  -1.1135894   2.131614  ]\n",
      " [ 0.2645259   0.04332668  0.04937216]\n",
      " [ 0.5658914   0.28292277 -0.4217938 ]]\n",
      "158 0.60614836 [[-0.94167477 -1.1151427   2.1368442 ]\n",
      " [ 0.2642901   0.04396409  0.04897055]\n",
      " [ 0.56763846  0.2831017  -0.42371976]]\n",
      "159 0.6052105 [[-0.9453472  -1.1166764   2.1420503 ]\n",
      " [ 0.26406416  0.04459314  0.04856743]\n",
      " [ 0.569373    0.28328037 -0.425633  ]]\n",
      "160 0.6042804 [[-0.9490151  -1.1181908   2.1472325 ]\n",
      " [ 0.26384774  0.04521414  0.04816286]\n",
      " [ 0.5710953   0.2834589  -0.42753378]]\n",
      "161 0.60335827 [[-0.95267844 -1.119686    2.1523912 ]\n",
      " [ 0.2636406   0.04582714  0.04775698]\n",
      " [ 0.5728056   0.28363702 -0.42942223]]\n",
      "162 0.6024438 [[-0.9563373  -1.1211624   2.1575265 ]\n",
      " [ 0.26344246  0.04643241  0.04734987]\n",
      " [ 0.57450414  0.28381485 -0.43129864]]\n",
      "163 0.60153675 [[-0.9599916  -1.1226202   2.1626387 ]\n",
      " [ 0.26325306  0.04703002  0.04694166]\n",
      " [ 0.5761913   0.2839922  -0.4331632 ]]\n",
      "164 0.6006372 [[-0.96364135 -1.1240597   2.167728  ]\n",
      " [ 0.26307216  0.04762018  0.0465324 ]\n",
      " [ 0.5778673   0.28416908 -0.43501613]]\n",
      "165 0.5997449 [[-0.9672865  -1.125481    2.1727946 ]\n",
      " [ 0.26289943  0.04820308  0.04612223]\n",
      " [ 0.57953244  0.28434545 -0.4368576 ]]\n",
      "166 0.59885985 [[-0.9709272  -1.1268845   2.1778386 ]\n",
      " [ 0.2627347   0.04877881  0.04571123]\n",
      " [ 0.58118695  0.2845212  -0.43868786]]\n",
      "167 0.5979818 [[-0.97456324 -1.1282703   2.1828604 ]\n",
      " [ 0.26257774  0.04934754  0.04529947]\n",
      " [ 0.582831    0.2846963  -0.44050708]]\n",
      "168 0.59711075 [[-0.9781948  -1.1296386   2.1878603 ]\n",
      " [ 0.2624283   0.0499094   0.04488705]\n",
      " [ 0.58446497  0.2848707  -0.44231546]]\n",
      "169 0.5962465 [[-0.9818217  -1.1309897   2.1928382 ]\n",
      " [ 0.26228616  0.05046453  0.04447405]\n",
      " [ 0.586089    0.28504437 -0.4441132 ]]\n",
      "170 0.5953889 [[-0.9854441  -1.1323237   2.1977947 ]\n",
      " [ 0.26215106  0.0510131   0.04406056]\n",
      " [ 0.58770335  0.2852173  -0.44590044]]\n",
      "171 0.59453803 [[-0.98906195 -1.133641    2.2027297 ]\n",
      " [ 0.26202288  0.05155519  0.04364666]\n",
      " [ 0.58930826  0.28538933 -0.4476774 ]]\n",
      "172 0.5936936 [[-0.99267524 -1.1349417   2.2076437 ]\n",
      " [ 0.26190132  0.052091    0.04323243]\n",
      " [ 0.5909039   0.28556055 -0.44944423]]\n",
      "173 0.5928555 [[-0.99628395 -1.136226    2.2125368 ]\n",
      " [ 0.26178625  0.05262058  0.04281793]\n",
      " [ 0.59249055  0.28573084 -0.45120114]]\n",
      "174 0.59202385 [[-0.9998881  -1.1374942   2.2174091 ]\n",
      " [ 0.26167738  0.05314413  0.04240324]\n",
      " [ 0.59406835  0.2859002  -0.4529483 ]]\n",
      "175 0.5911983 [[-1.0034877  -1.1387464   2.222261  ]\n",
      " [ 0.26157466  0.05366167  0.04198843]\n",
      " [ 0.59563756  0.28606853 -0.45468584]]\n",
      "176 0.59037894 [[-1.0070827  -1.1399828   2.2270925 ]\n",
      " [ 0.26147777  0.05417345  0.04157357]\n",
      " [ 0.5971983   0.2862359  -0.45641395]]\n",
      "177 0.5895656 [[-1.0106732  -1.1412036   2.2319038 ]\n",
      " [ 0.2613866   0.05467944  0.04115872]\n",
      " [ 0.5987509   0.28640217 -0.45813277]]\n",
      "178 0.5887581 [[-1.0142591  -1.1424091   2.236695  ]\n",
      " [ 0.26130092  0.05517988  0.04074395]\n",
      " [ 0.60029536  0.2865674  -0.45984247]]\n",
      "179 0.5879565 [[-1.0178405  -1.1435993   2.2414668 ]\n",
      " [ 0.26122066  0.05567478  0.04032932]\n",
      " [ 0.60183203  0.28673145 -0.4615432 ]]\n",
      "180 0.5871607 [[-1.0214174  -1.1447744   2.2462187 ]\n",
      " [ 0.26114553  0.05616434  0.0399149 ]\n",
      " [ 0.60336095  0.28689444 -0.4632351 ]]\n",
      "181 0.5863706 [[-1.0249897  -1.1459348   2.2509513 ]\n",
      " [ 0.2610755   0.05664852  0.03950075]\n",
      " [ 0.6048824   0.28705618 -0.46491832]]\n",
      "182 0.58558595 [[-1.0285575  -1.1470805   2.2556648 ]\n",
      " [ 0.26101023  0.05712762  0.03908692]\n",
      " [ 0.60639644  0.2872168  -0.466593  ]]\n",
      "183 0.5848069 [[-1.0321207  -1.1482117   2.2603593 ]\n",
      " [ 0.2609498   0.05760153  0.03867345]\n",
      " [ 0.6079034   0.28737614 -0.46825927]]\n",
      "184 0.58403325 [[-1.0356795  -1.1493286   2.265035  ]\n",
      " [ 0.26089382  0.05807054  0.0382604 ]\n",
      " [ 0.6094033   0.28753433 -0.46991733]]\n",
      "185 0.58326495 [[-1.0392337  -1.1504314   2.269692  ]\n",
      " [ 0.26084232  0.0585346   0.03784784]\n",
      " [ 0.61089635  0.28769118 -0.4715672 ]]\n",
      "186 0.5825019 [[-1.0427834  -1.1515201   2.2743304 ]\n",
      " [ 0.2607951   0.05899386  0.03743579]\n",
      " [ 0.6123827   0.28784674 -0.47320914]]\n",
      "187 0.581744 [[-1.0463285  -1.1525952   2.2789505 ]\n",
      " [ 0.260752    0.05944841  0.03702432]\n",
      " [ 0.61386245  0.288001   -0.4748432 ]]\n",
      "188 0.5809913 [[-1.0498692  -1.1536565   2.2835524 ]\n",
      " [ 0.2607129   0.05989835  0.03661348]\n",
      " [ 0.6153358   0.28815398 -0.47646952]]\n",
      "189 0.5802436 [[-1.0534053  -1.1547043   2.2881365 ]\n",
      " [ 0.26067773  0.0603437   0.03620331]\n",
      " [ 0.61680293  0.28830555 -0.4780882 ]]\n",
      "190 0.5795009 [[-1.056937   -1.1557388   2.2927027 ]\n",
      " [ 0.26064625  0.06078464  0.03579384]\n",
      " [ 0.61826384  0.2884558  -0.4796994 ]]\n",
      "191 0.5787631 [[-1.0604641  -1.1567602   2.2972512 ]\n",
      " [ 0.26061845  0.06122116  0.03538512]\n",
      " [ 0.6197188   0.28860468 -0.48130322]]\n",
      "192 0.5780301 [[-1.0639869  -1.1577686   2.3017824 ]\n",
      " [ 0.26059413  0.06165342  0.0349772 ]\n",
      " [ 0.62116784  0.28875217 -0.48289979]]\n",
      "193 0.577302 [[-1.0675051  -1.1587641   2.306296  ]\n",
      " [ 0.2605732   0.06208144  0.0345701 ]\n",
      " [ 0.62261117  0.28889826 -0.4844892 ]]\n",
      "194 0.57657844 [[-1.0710189  -1.1597469   2.3107927 ]\n",
      " [ 0.26055557  0.06250531  0.03416387]\n",
      " [ 0.6240489   0.28904292 -0.4860716 ]]\n",
      "195 0.5758596 [[-1.0745282  -1.1607171   2.315272  ]\n",
      " [ 0.26054108  0.06292512  0.03375856]\n",
      " [ 0.62548107  0.28918615 -0.48764703]]\n",
      "196 0.57514536 [[-1.0780331  -1.1616749   2.3197348 ]\n",
      " [ 0.26052964  0.06334093  0.03335419]\n",
      " [ 0.6269079   0.28932795 -0.48921564]]\n",
      "197 0.5744356 [[-1.0815336  -1.1626203   2.3241808 ]\n",
      " [ 0.26052117  0.06375279  0.03295079]\n",
      " [ 0.62832946  0.2894683  -0.49077755]]\n",
      "198 0.57373035 [[-1.0850296  -1.1635536   2.3286102 ]\n",
      " [ 0.26051554  0.06416082  0.0325484 ]\n",
      " [ 0.62974584  0.2896072  -0.49233282]]\n",
      "199 0.57302946 [[-1.0885212  -1.164475    2.333023  ]\n",
      " [ 0.26051268  0.06456502  0.03214706]\n",
      " [ 0.6311572   0.28974462 -0.49388158]]\n",
      "200 0.57233286 [[-1.0920085  -1.1653844   2.3374197 ]\n",
      " [ 0.26051244  0.06496552  0.03174678]\n",
      " [ 0.6325636   0.28988057 -0.4954239 ]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Data set\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "# Try to change learning_rate to small numbers\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "\n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  1544700800000.0 \n",
      "Prediction:\n",
      " [[ -876824.1]\n",
      " [-1762947.1]\n",
      " [-1387293.2]\n",
      " [ -973110.9]\n",
      " [-1146492.6]\n",
      " [-1156125.2]\n",
      " [-1059785.9]\n",
      " [-1348744.4]]\n",
      "1 Cost:  1.697132e+27 \n",
      "Prediction:\n",
      " [[2.9059566e+13]\n",
      " [5.8499887e+13]\n",
      " [4.6019752e+13]\n",
      " [3.2259602e+13]\n",
      " [3.8019663e+13]\n",
      " [3.8339667e+13]\n",
      " [3.5139629e+13]\n",
      " [4.4739735e+13]]\n",
      "2 Cost:  inf \n",
      "Prediction:\n",
      " [[-9.63218629e+20]\n",
      " [-1.93905789e+21]\n",
      " [-1.52538693e+21]\n",
      " [-1.06928804e+21]\n",
      " [-1.26021315e+21]\n",
      " [-1.27082011e+21]\n",
      " [-1.16475056e+21]\n",
      " [-1.48295908e+21]]\n",
      "3 Cost:  inf \n",
      "Prediction:\n",
      " [[3.1927185e+28]\n",
      " [6.4272697e+28]\n",
      " [5.0561013e+28]\n",
      " [3.5443001e+28]\n",
      " [4.1771475e+28]\n",
      " [4.2123056e+28]\n",
      " [3.8607233e+28]\n",
      " [4.9154688e+28]]\n",
      "4 Cost:  inf \n",
      "Prediction:\n",
      " [[-1.05826958e+36]\n",
      " [-2.13040536e+36]\n",
      " [-1.67591300e+36]\n",
      " [-1.17480605e+36]\n",
      " [-1.38457188e+36]\n",
      " [-1.39622555e+36]\n",
      " [-1.27968884e+36]\n",
      " [-1.62929832e+36]]\n",
      "5 Cost:  inf \n",
      "Prediction:\n",
      " [[inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "6 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "7 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "8 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "9 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "10 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "11 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "12 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "13 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "14 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "15 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "16 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "17 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "18 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "19 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "20 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "21 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "22 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "23 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "24 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "25 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "26 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "27 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "28 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "29 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "30 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "31 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "32 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "33 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "34 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "35 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "36 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "37 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "38 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "39 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "40 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "41 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "42 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "43 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "44 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "45 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "46 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "47 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "48 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "49 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "51 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "52 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "53 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "54 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "55 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "56 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "57 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "58 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "59 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "60 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "61 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "62 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "63 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "64 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "65 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "66 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "67 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "68 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "69 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "71 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "72 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "73 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "74 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "75 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "76 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "77 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "78 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "79 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "81 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "82 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "83 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "84 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "85 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "86 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "87 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "88 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "89 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "91 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "92 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "93 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "94 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "95 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "96 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "97 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "98 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "99 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
      " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
      "0 Cost:  3.1630816 \n",
      "Prediction:\n",
      " [[2.9790847]\n",
      " [3.3338928]\n",
      " [2.6440837]\n",
      " [1.8158243]\n",
      " [2.3318493]\n",
      " [2.1413546]\n",
      " [1.3979485]\n",
      " [1.2270535]]\n",
      "1 Cost:  3.162842 \n",
      "Prediction:\n",
      " [[2.9789958]\n",
      " [3.333805 ]\n",
      " [2.6440105]\n",
      " [1.8157678]\n",
      " [2.3317823]\n",
      " [2.14129  ]\n",
      " [1.3979046]\n",
      " [1.22701  ]]\n",
      "2 Cost:  3.1626024 \n",
      "Prediction:\n",
      " [[2.9789069]\n",
      " [3.3337173]\n",
      " [2.6439376]\n",
      " [1.8157113]\n",
      " [2.3317156]\n",
      " [2.1412253]\n",
      " [1.3978606]\n",
      " [1.2269664]]\n",
      "3 Cost:  3.1623626 \n",
      "Prediction:\n",
      " [[2.9788177]\n",
      " [3.3336298]\n",
      " [2.6438646]\n",
      " [1.8156548]\n",
      " [2.3316488]\n",
      " [2.1411605]\n",
      " [1.3978168]\n",
      " [1.2269228]]\n",
      "4 Cost:  3.1621232 \n",
      "Prediction:\n",
      " [[2.9787288]\n",
      " [3.333542 ]\n",
      " [2.6437917]\n",
      " [1.8155982]\n",
      " [2.3315818]\n",
      " [2.1410959]\n",
      " [1.3977729]\n",
      " [1.2268791]]\n",
      "5 Cost:  3.1618836 \n",
      "Prediction:\n",
      " [[2.9786398]\n",
      " [3.3334544]\n",
      " [2.6437185]\n",
      " [1.8155417]\n",
      " [2.331515 ]\n",
      " [2.1410313]\n",
      " [1.3977289]\n",
      " [1.2268355]]\n",
      "6 Cost:  3.161644 \n",
      "Prediction:\n",
      " [[2.978551 ]\n",
      " [3.3333664]\n",
      " [2.6436455]\n",
      " [1.8154852]\n",
      " [2.331448 ]\n",
      " [2.1409667]\n",
      " [1.397685 ]\n",
      " [1.2267919]]\n",
      "7 Cost:  3.1614041 \n",
      "Prediction:\n",
      " [[2.9784617]\n",
      " [3.333279 ]\n",
      " [2.6435723]\n",
      " [1.8154287]\n",
      " [2.3313813]\n",
      " [2.140902 ]\n",
      " [1.3976412]\n",
      " [1.2267482]]\n",
      "8 Cost:  3.1611652 \n",
      "Prediction:\n",
      " [[2.9783728]\n",
      " [3.3331914]\n",
      " [2.6434994]\n",
      " [1.8153722]\n",
      " [2.3313146]\n",
      " [2.1408372]\n",
      " [1.3975973]\n",
      " [1.2267047]]\n",
      "9 Cost:  3.1609256 \n",
      "Prediction:\n",
      " [[2.978284 ]\n",
      " [3.3331037]\n",
      " [2.6434264]\n",
      " [1.8153157]\n",
      " [2.3312476]\n",
      " [2.1407726]\n",
      " [1.3975534]\n",
      " [1.2266612]]\n",
      "10 Cost:  3.160686 \n",
      "Prediction:\n",
      " [[2.9781947]\n",
      " [3.333016 ]\n",
      " [2.6433535]\n",
      " [1.8152591]\n",
      " [2.3311808]\n",
      " [2.140708 ]\n",
      " [1.3975095]\n",
      " [1.2266176]]\n",
      "11 Cost:  3.1604466 \n",
      "Prediction:\n",
      " [[2.9781058]\n",
      " [3.3329282]\n",
      " [2.6432803]\n",
      " [1.8152026]\n",
      " [2.331114 ]\n",
      " [2.1406434]\n",
      " [1.3974656]\n",
      " [1.226574 ]]\n",
      "12 Cost:  3.160207 \n",
      "Prediction:\n",
      " [[2.9780169]\n",
      " [3.3328404]\n",
      " [2.6432073]\n",
      " [1.8151462]\n",
      " [2.331047 ]\n",
      " [2.1405787]\n",
      " [1.3974216]\n",
      " [1.2265303]]\n",
      "13 Cost:  3.1599674 \n",
      "Prediction:\n",
      " [[2.977928 ]\n",
      " [3.332753 ]\n",
      " [2.643134 ]\n",
      " [1.8150897]\n",
      " [2.3309803]\n",
      " [2.1405141]\n",
      " [1.3973777]\n",
      " [1.2264867]]\n",
      "14 Cost:  3.159728 \n",
      "Prediction:\n",
      " [[2.977839 ]\n",
      " [3.3326652]\n",
      " [2.6430612]\n",
      " [1.8150332]\n",
      " [2.3309133]\n",
      " [2.1404495]\n",
      " [1.3973339]\n",
      " [1.226443 ]]\n",
      "15 Cost:  3.1594884 \n",
      "Prediction:\n",
      " [[2.9777498]\n",
      " [3.3325775]\n",
      " [2.6429882]\n",
      " [1.8149766]\n",
      " [2.3308465]\n",
      " [2.1403847]\n",
      " [1.39729  ]\n",
      " [1.2263995]]\n",
      "16 Cost:  3.1592488 \n",
      "Prediction:\n",
      " [[2.977661 ]\n",
      " [3.3324897]\n",
      " [2.642915 ]\n",
      " [1.8149202]\n",
      " [2.3307798]\n",
      " [2.14032  ]\n",
      " [1.397246 ]\n",
      " [1.226356 ]]\n",
      "17 Cost:  3.1590095 \n",
      "Prediction:\n",
      " [[2.977572 ]\n",
      " [3.332402 ]\n",
      " [2.6428423]\n",
      " [1.8148636]\n",
      " [2.3307128]\n",
      " [2.1402555]\n",
      " [1.3972021]\n",
      " [1.2263124]]\n",
      "18 Cost:  3.1587703 \n",
      "Prediction:\n",
      " [[2.9774828]\n",
      " [3.3323145]\n",
      " [2.642769 ]\n",
      " [1.814807 ]\n",
      " [2.330646 ]\n",
      " [2.1401908]\n",
      " [1.3971583]\n",
      " [1.2262688]]\n",
      "19 Cost:  3.1585302 \n",
      "Prediction:\n",
      " [[2.9773939]\n",
      " [3.3322265]\n",
      " [2.642696 ]\n",
      " [1.8147506]\n",
      " [2.3305793]\n",
      " [2.1401262]\n",
      " [1.3971143]\n",
      " [1.2262251]]\n",
      "20 Cost:  3.1582913 \n",
      "Prediction:\n",
      " [[2.977305 ]\n",
      " [3.332139 ]\n",
      " [2.642623 ]\n",
      " [1.814694 ]\n",
      " [2.3305123]\n",
      " [2.1400614]\n",
      " [1.3970704]\n",
      " [1.2261815]]\n",
      "21 Cost:  3.158052 \n",
      "Prediction:\n",
      " [[2.977216 ]\n",
      " [3.3320513]\n",
      " [2.64255  ]\n",
      " [1.8146375]\n",
      " [2.3304455]\n",
      " [2.139997 ]\n",
      " [1.3970265]\n",
      " [1.2261379]]\n",
      "22 Cost:  3.1578126 \n",
      "Prediction:\n",
      " [[2.977127 ]\n",
      " [3.3319635]\n",
      " [2.6424768]\n",
      " [1.814581 ]\n",
      " [2.3303785]\n",
      " [2.1399322]\n",
      " [1.3969827]\n",
      " [1.2260944]]\n",
      "23 Cost:  3.1575732 \n",
      "Prediction:\n",
      " [[2.977038 ]\n",
      " [3.331876 ]\n",
      " [2.6424038]\n",
      " [1.8145244]\n",
      " [2.3303118]\n",
      " [2.1398678]\n",
      " [1.3969387]\n",
      " [1.2260509]]\n",
      "24 Cost:  3.1573339 \n",
      "Prediction:\n",
      " [[2.976949 ]\n",
      " [3.3317883]\n",
      " [2.642331 ]\n",
      " [1.8144679]\n",
      " [2.330245 ]\n",
      " [2.139803 ]\n",
      " [1.3968948]\n",
      " [1.2260072]]\n",
      "25 Cost:  3.157094 \n",
      "Prediction:\n",
      " [[2.97686  ]\n",
      " [3.3317006]\n",
      " [2.6422577]\n",
      " [1.8144114]\n",
      " [2.330178 ]\n",
      " [2.1397383]\n",
      " [1.396851 ]\n",
      " [1.2259636]]\n",
      "26 Cost:  3.1568549 \n",
      "Prediction:\n",
      " [[2.9767709]\n",
      " [3.3316128]\n",
      " [2.6421847]\n",
      " [1.814355 ]\n",
      " [2.3301113]\n",
      " [2.1396737]\n",
      " [1.396807 ]\n",
      " [1.22592  ]]\n",
      "27 Cost:  3.1566157 \n",
      "Prediction:\n",
      " [[2.976682 ]\n",
      " [3.331525 ]\n",
      " [2.6421118]\n",
      " [1.8142986]\n",
      " [2.3300445]\n",
      " [2.139609 ]\n",
      " [1.3967631]\n",
      " [1.2258765]]\n",
      "28 Cost:  3.1563766 \n",
      "Prediction:\n",
      " [[2.976593 ]\n",
      " [3.3314376]\n",
      " [2.6420388]\n",
      " [1.814242 ]\n",
      " [2.3299775]\n",
      " [2.1395445]\n",
      " [1.3967193]\n",
      " [1.2258329]]\n",
      "29 Cost:  3.1561377 \n",
      "Prediction:\n",
      " [[2.9765043]\n",
      " [3.33135  ]\n",
      " [2.6419659]\n",
      " [1.8141856]\n",
      " [2.329911 ]\n",
      " [2.1394799]\n",
      " [1.3966755]\n",
      " [1.2257893]]\n",
      "30 Cost:  3.1558983 \n",
      "Prediction:\n",
      " [[2.9764154]\n",
      " [3.3312624]\n",
      " [2.641893 ]\n",
      " [1.8141291]\n",
      " [2.3298442]\n",
      " [2.1394153]\n",
      " [1.3966316]\n",
      " [1.2257459]]\n",
      "31 Cost:  3.1556594 \n",
      "Prediction:\n",
      " [[2.9763262]\n",
      " [3.3311749]\n",
      " [2.64182  ]\n",
      " [1.8140726]\n",
      " [2.3297772]\n",
      " [2.1393507]\n",
      " [1.3965878]\n",
      " [1.2257023]]\n",
      "32 Cost:  3.1554203 \n",
      "Prediction:\n",
      " [[2.9762373]\n",
      " [3.331087 ]\n",
      " [2.641747 ]\n",
      " [1.8140162]\n",
      " [2.3297105]\n",
      " [2.139286 ]\n",
      " [1.396544 ]\n",
      " [1.2256588]]\n",
      "33 Cost:  3.1551814 \n",
      "Prediction:\n",
      " [[2.9761486]\n",
      " [3.3309996]\n",
      " [2.641674 ]\n",
      " [1.8139598]\n",
      " [2.329644 ]\n",
      " [2.1392217]\n",
      " [1.3965001]\n",
      " [1.2256153]]\n",
      "34 Cost:  3.1549425 \n",
      "Prediction:\n",
      " [[2.9760597]\n",
      " [3.330912 ]\n",
      " [2.641601 ]\n",
      " [1.8139033]\n",
      " [2.329577 ]\n",
      " [2.139157 ]\n",
      " [1.3964562]\n",
      " [1.2255718]]\n",
      "35 Cost:  3.154703 \n",
      "Prediction:\n",
      " [[2.9759707]\n",
      " [3.3308241]\n",
      " [2.641528 ]\n",
      " [1.8138468]\n",
      " [2.3295102]\n",
      " [2.1390924]\n",
      " [1.3964124]\n",
      " [1.2255282]]\n",
      "36 Cost:  3.154464 \n",
      "Prediction:\n",
      " [[2.9758816]\n",
      " [3.3307366]\n",
      " [2.6414552]\n",
      " [1.8137904]\n",
      " [2.3294435]\n",
      " [2.1390278]\n",
      " [1.3963685]\n",
      " [1.2254846]]\n",
      "37 Cost:  3.1542249 \n",
      "Prediction:\n",
      " [[2.975793 ]\n",
      " [3.3306491]\n",
      " [2.641382 ]\n",
      " [1.813734 ]\n",
      " [2.3293767]\n",
      " [2.1389635]\n",
      " [1.3963246]\n",
      " [1.2254412]]\n",
      "38 Cost:  3.153986 \n",
      "Prediction:\n",
      " [[2.975704 ]\n",
      " [3.3305614]\n",
      " [2.6413093]\n",
      " [1.8136775]\n",
      " [2.32931  ]\n",
      " [2.1388988]\n",
      " [1.3962809]\n",
      " [1.2253976]]\n",
      "39 Cost:  3.1537473 \n",
      "Prediction:\n",
      " [[2.9756153]\n",
      " [3.330474 ]\n",
      " [2.6412363]\n",
      " [1.8136213]\n",
      " [2.3292432]\n",
      " [2.1388342]\n",
      " [1.3962371]\n",
      " [1.2253541]]\n",
      "40 Cost:  3.1535087 \n",
      "Prediction:\n",
      " [[2.9755263]\n",
      " [3.3303866]\n",
      " [2.6411633]\n",
      " [1.8135648]\n",
      " [2.3291764]\n",
      " [2.1387696]\n",
      " [1.3961933]\n",
      " [1.2253106]]\n",
      "41 Cost:  3.1532698 \n",
      "Prediction:\n",
      " [[2.9754376]\n",
      " [3.330299 ]\n",
      " [2.6410904]\n",
      " [1.8135083]\n",
      " [2.32911  ]\n",
      " [2.138705 ]\n",
      " [1.3961494]\n",
      " [1.2252669]]\n",
      "42 Cost:  3.1530306 \n",
      "Prediction:\n",
      " [[2.9753487]\n",
      " [3.3302112]\n",
      " [2.6410174]\n",
      " [1.813452 ]\n",
      " [2.329043 ]\n",
      " [2.1386404]\n",
      " [1.3961055]\n",
      " [1.2252235]]\n",
      "43 Cost:  3.1527915 \n",
      "Prediction:\n",
      " [[2.9752598]\n",
      " [3.3301237]\n",
      " [2.6409445]\n",
      " [1.8133955]\n",
      " [2.3289762]\n",
      " [2.138576 ]\n",
      " [1.3960617]\n",
      " [1.2251799]]\n",
      "44 Cost:  3.152553 \n",
      "Prediction:\n",
      " [[2.975171 ]\n",
      " [3.3300362]\n",
      " [2.6408715]\n",
      " [1.8133391]\n",
      " [2.3289094]\n",
      " [2.1385117]\n",
      " [1.3960179]\n",
      " [1.2251364]]\n",
      "45 Cost:  3.1523142 \n",
      "Prediction:\n",
      " [[2.9750822]\n",
      " [3.3299487]\n",
      " [2.6407986]\n",
      " [1.8132827]\n",
      " [2.3288426]\n",
      " [2.1384468]\n",
      " [1.3959739]\n",
      " [1.2250929]]\n",
      "46 Cost:  3.1520748 \n",
      "Prediction:\n",
      " [[2.9749932]\n",
      " [3.329861 ]\n",
      " [2.6407256]\n",
      " [1.8132262]\n",
      " [2.328776 ]\n",
      " [2.1383824]\n",
      " [1.3959302]\n",
      " [1.2250493]]\n",
      "47 Cost:  3.1518364 \n",
      "Prediction:\n",
      " [[2.9749043]\n",
      " [3.3297734]\n",
      " [2.6406527]\n",
      " [1.8131697]\n",
      " [2.3287091]\n",
      " [2.1383178]\n",
      " [1.3958864]\n",
      " [1.2250057]]\n",
      "48 Cost:  3.1515975 \n",
      "Prediction:\n",
      " [[2.9748154]\n",
      " [3.3296857]\n",
      " [2.6405797]\n",
      " [1.8131133]\n",
      " [2.3286424]\n",
      " [2.1382532]\n",
      " [1.3958426]\n",
      " [1.2249622]]\n",
      "49 Cost:  3.1513586 \n",
      "Prediction:\n",
      " [[2.9747267]\n",
      " [3.3295982]\n",
      " [2.6405067]\n",
      " [1.813057 ]\n",
      " [2.3285758]\n",
      " [2.1381886]\n",
      " [1.3957987]\n",
      " [1.2249187]]\n",
      "50 Cost:  3.1511197 \n",
      "Prediction:\n",
      " [[2.9746377]\n",
      " [3.3295107]\n",
      " [2.6404338]\n",
      " [1.8130004]\n",
      " [2.3285089]\n",
      " [2.1381242]\n",
      " [1.3957548]\n",
      " [1.2248752]]\n",
      "51 Cost:  3.150881 \n",
      "Prediction:\n",
      " [[2.9745488]\n",
      " [3.3294232]\n",
      " [2.640361 ]\n",
      " [1.8129439]\n",
      " [2.3284423]\n",
      " [2.1380596]\n",
      " [1.395711 ]\n",
      " [1.2248316]]\n",
      "52 Cost:  3.1506424 \n",
      "Prediction:\n",
      " [[2.9744601]\n",
      " [3.3293357]\n",
      " [2.640288 ]\n",
      " [1.8128877]\n",
      " [2.3283756]\n",
      " [2.137995 ]\n",
      " [1.3956672]\n",
      " [1.2247882]]\n",
      "53 Cost:  3.150404 \n",
      "Prediction:\n",
      " [[2.9743714]\n",
      " [3.329248 ]\n",
      " [2.6402152]\n",
      " [1.8128314]\n",
      " [2.3283088]\n",
      " [2.1379306]\n",
      " [1.3956233]\n",
      " [1.2247446]]\n",
      "54 Cost:  3.150165 \n",
      "Prediction:\n",
      " [[2.9742825]\n",
      " [3.3291605]\n",
      " [2.6401424]\n",
      " [1.8127749]\n",
      " [2.328242 ]\n",
      " [2.137866 ]\n",
      " [1.3955796]\n",
      " [1.2247012]]\n",
      "55 Cost:  3.1499264 \n",
      "Prediction:\n",
      " [[2.9741936]\n",
      " [3.329073 ]\n",
      " [2.6400692]\n",
      " [1.8127184]\n",
      " [2.3281753]\n",
      " [2.1378014]\n",
      " [1.3955357]\n",
      " [1.2246575]]\n",
      "56 Cost:  3.149688 \n",
      "Prediction:\n",
      " [[2.974105 ]\n",
      " [3.3289857]\n",
      " [2.6399965]\n",
      " [1.812662 ]\n",
      " [2.3281088]\n",
      " [2.1377368]\n",
      " [1.3954918]\n",
      " [1.2246141]]\n",
      "57 Cost:  3.1494493 \n",
      "Prediction:\n",
      " [[2.974016 ]\n",
      " [3.3288982]\n",
      " [2.6399236]\n",
      " [1.8126056]\n",
      " [2.328042 ]\n",
      " [2.1376724]\n",
      " [1.395448 ]\n",
      " [1.2245705]]\n",
      "58 Cost:  3.1492107 \n",
      "Prediction:\n",
      " [[2.973927 ]\n",
      " [3.3288107]\n",
      " [2.6398506]\n",
      " [1.8125491]\n",
      " [2.3279753]\n",
      " [2.137608 ]\n",
      " [1.3954042]\n",
      " [1.2245271]]\n",
      "59 Cost:  3.148972 \n",
      "Prediction:\n",
      " [[2.973838 ]\n",
      " [3.328723 ]\n",
      " [2.639778 ]\n",
      " [1.8124926]\n",
      " [2.3279085]\n",
      " [2.1375434]\n",
      " [1.3953605]\n",
      " [1.2244836]]\n",
      "60 Cost:  3.1487334 \n",
      "Prediction:\n",
      " [[2.9737492]\n",
      " [3.3286357]\n",
      " [2.639705 ]\n",
      " [1.8124363]\n",
      " [2.3278418]\n",
      " [2.1374788]\n",
      " [1.3953166]\n",
      " [1.2244401]]\n",
      "61 Cost:  3.1484947 \n",
      "Prediction:\n",
      " [[2.9736607]\n",
      " [3.328548 ]\n",
      " [2.639632 ]\n",
      " [1.8123798]\n",
      " [2.327775 ]\n",
      " [2.1374142]\n",
      " [1.3952727]\n",
      " [1.2243966]]\n",
      "62 Cost:  3.148256 \n",
      "Prediction:\n",
      " [[2.9735718]\n",
      " [3.3284605]\n",
      " [2.6395593]\n",
      " [1.8123235]\n",
      " [2.3277082]\n",
      " [2.1373498]\n",
      " [1.395229 ]\n",
      " [1.2243531]]\n",
      "63 Cost:  3.1480174 \n",
      "Prediction:\n",
      " [[2.9734828]\n",
      " [3.328373 ]\n",
      " [2.639486 ]\n",
      " [1.8122671]\n",
      " [2.3276415]\n",
      " [2.1372852]\n",
      " [1.3951851]\n",
      " [1.2243096]]\n",
      "64 Cost:  3.147779 \n",
      "Prediction:\n",
      " [[2.973394 ]\n",
      " [3.3282857]\n",
      " [2.6394134]\n",
      " [1.8122107]\n",
      " [2.3275747]\n",
      " [2.1372209]\n",
      " [1.3951412]\n",
      " [1.224266 ]]\n",
      "65 Cost:  3.1475406 \n",
      "Prediction:\n",
      " [[2.9733052]\n",
      " [3.328198 ]\n",
      " [2.6393404]\n",
      " [1.8121543]\n",
      " [2.3275082]\n",
      " [2.1371562]\n",
      " [1.3950975]\n",
      " [1.2242225]]\n",
      "66 Cost:  3.1473017 \n",
      "Prediction:\n",
      " [[2.9732163]\n",
      " [3.3281105]\n",
      " [2.6392674]\n",
      " [1.8120978]\n",
      " [2.3274415]\n",
      " [2.1370916]\n",
      " [1.3950536]\n",
      " [1.224179 ]]\n",
      "67 Cost:  3.1470633 \n",
      "Prediction:\n",
      " [[2.9731274]\n",
      " [3.328023 ]\n",
      " [2.6391947]\n",
      " [1.8120415]\n",
      " [2.3273747]\n",
      " [2.1370273]\n",
      " [1.3950098]\n",
      " [1.2241356]]\n",
      "68 Cost:  3.1468246 \n",
      "Prediction:\n",
      " [[2.9730387]\n",
      " [3.3279352]\n",
      " [2.6391218]\n",
      " [1.811985 ]\n",
      " [2.327308 ]\n",
      " [2.1369627]\n",
      " [1.394966 ]\n",
      " [1.224092 ]]\n",
      "69 Cost:  3.1465864 \n",
      "Prediction:\n",
      " [[2.97295  ]\n",
      " [3.327848 ]\n",
      " [2.6390488]\n",
      " [1.8119285]\n",
      " [2.3272412]\n",
      " [2.136898 ]\n",
      " [1.3949223]\n",
      " [1.2240486]]\n",
      "70 Cost:  3.1463478 \n",
      "Prediction:\n",
      " [[2.972861 ]\n",
      " [3.3277605]\n",
      " [2.6389759]\n",
      " [1.8118722]\n",
      " [2.3271747]\n",
      " [2.1368337]\n",
      " [1.3948784]\n",
      " [1.2240051]]\n",
      "71 Cost:  3.146109 \n",
      "Prediction:\n",
      " [[2.9727721]\n",
      " [3.327673 ]\n",
      " [2.638903 ]\n",
      " [1.8118157]\n",
      " [2.327108 ]\n",
      " [2.136769 ]\n",
      " [1.3948345]\n",
      " [1.2239616]]\n",
      "72 Cost:  3.1458712 \n",
      "Prediction:\n",
      " [[2.9726834]\n",
      " [3.3275857]\n",
      " [2.6388302]\n",
      " [1.8117594]\n",
      " [2.3270411]\n",
      " [2.1367044]\n",
      " [1.3947906]\n",
      " [1.2239181]]\n",
      "73 Cost:  3.1456325 \n",
      "Prediction:\n",
      " [[2.9725945]\n",
      " [3.3274982]\n",
      " [2.6387572]\n",
      " [1.811703 ]\n",
      " [2.3269744]\n",
      " [2.13664  ]\n",
      " [1.3947469]\n",
      " [1.2238746]]\n",
      "74 Cost:  3.1453943 \n",
      "Prediction:\n",
      " [[2.9725056]\n",
      " [3.3274107]\n",
      " [2.6386845]\n",
      " [1.8116466]\n",
      " [2.3269076]\n",
      " [2.1365757]\n",
      " [1.3947031]\n",
      " [1.2238312]]\n",
      "75 Cost:  3.145156 \n",
      "Prediction:\n",
      " [[2.9724169]\n",
      " [3.3273232]\n",
      " [2.6386118]\n",
      " [1.8115902]\n",
      " [2.326841 ]\n",
      " [2.136511 ]\n",
      " [1.3946594]\n",
      " [1.2237878]]\n",
      "76 Cost:  3.1449177 \n",
      "Prediction:\n",
      " [[2.9723282]\n",
      " [3.3272357]\n",
      " [2.6385388]\n",
      " [1.8115339]\n",
      " [2.3267746]\n",
      " [2.1364467]\n",
      " [1.3946157]\n",
      " [1.2237443]]\n",
      "77 Cost:  3.1446793 \n",
      "Prediction:\n",
      " [[2.9722395]\n",
      " [3.3271482]\n",
      " [2.638466 ]\n",
      " [1.8114775]\n",
      " [2.3267078]\n",
      " [2.136382 ]\n",
      " [1.3945719]\n",
      " [1.2237009]]\n",
      "78 Cost:  3.1444411 \n",
      "Prediction:\n",
      " [[2.9721508]\n",
      " [3.3270607]\n",
      " [2.6383932]\n",
      " [1.8114213]\n",
      " [2.326641 ]\n",
      " [2.1363177]\n",
      " [1.3945282]\n",
      " [1.2236574]]\n",
      "79 Cost:  3.1442032 \n",
      "Prediction:\n",
      " [[2.9720619]\n",
      " [3.3269734]\n",
      " [2.6383204]\n",
      " [1.8113649]\n",
      " [2.3265743]\n",
      " [2.1362534]\n",
      " [1.3944843]\n",
      " [1.223614 ]]\n",
      "80 Cost:  3.1439652 \n",
      "Prediction:\n",
      " [[2.9719734]\n",
      " [3.3268862]\n",
      " [2.6382475]\n",
      " [1.8113085]\n",
      " [2.326508 ]\n",
      " [2.136189 ]\n",
      " [1.3944405]\n",
      " [1.2235706]]\n",
      "81 Cost:  3.1437268 \n",
      "Prediction:\n",
      " [[2.9718845]\n",
      " [3.3267987]\n",
      " [2.6381748]\n",
      " [1.8112521]\n",
      " [2.326441 ]\n",
      " [2.1361244]\n",
      " [1.3943968]\n",
      " [1.2235271]]\n",
      "82 Cost:  3.1434886 \n",
      "Prediction:\n",
      " [[2.9717956]\n",
      " [3.3267112]\n",
      " [2.638102 ]\n",
      " [1.8111959]\n",
      " [2.3263745]\n",
      " [2.1360598]\n",
      " [1.394353 ]\n",
      " [1.2234836]]\n",
      "83 Cost:  3.1432505 \n",
      "Prediction:\n",
      " [[2.9717069]\n",
      " [3.3266234]\n",
      " [2.638029 ]\n",
      " [1.8111395]\n",
      " [2.3263078]\n",
      " [2.1359954]\n",
      " [1.3943093]\n",
      " [1.2234402]]\n",
      "84 Cost:  3.143012 \n",
      "Prediction:\n",
      " [[2.9716182]\n",
      " [3.3265362]\n",
      " [2.6379561]\n",
      " [1.8110832]\n",
      " [2.326241 ]\n",
      " [2.135931 ]\n",
      " [1.3942654]\n",
      " [1.2233968]]\n",
      "85 Cost:  3.1427739 \n",
      "Prediction:\n",
      " [[2.9715292]\n",
      " [3.3264487]\n",
      " [2.6378834]\n",
      " [1.8110268]\n",
      " [2.3261745]\n",
      " [2.1358666]\n",
      " [1.3942218]\n",
      " [1.2233533]]\n",
      "86 Cost:  3.1425357 \n",
      "Prediction:\n",
      " [[2.9714403]\n",
      " [3.3263612]\n",
      " [2.6378107]\n",
      " [1.8109704]\n",
      " [2.326108 ]\n",
      " [2.135802 ]\n",
      " [1.3941779]\n",
      " [1.2233099]]\n",
      "87 Cost:  3.1422977 \n",
      "Prediction:\n",
      " [[2.9713519]\n",
      " [3.326274 ]\n",
      " [2.6377378]\n",
      " [1.810914 ]\n",
      " [2.3260412]\n",
      " [2.1357377]\n",
      " [1.3941343]\n",
      " [1.2232664]]\n",
      "88 Cost:  3.1420596 \n",
      "Prediction:\n",
      " [[2.971263 ]\n",
      " [3.3261867]\n",
      " [2.6376648]\n",
      " [1.8108577]\n",
      " [2.3259745]\n",
      " [2.135673 ]\n",
      " [1.3940904]\n",
      " [1.223223 ]]\n",
      "89 Cost:  3.1418214 \n",
      "Prediction:\n",
      " [[2.9711742]\n",
      " [3.3260992]\n",
      " [2.637592 ]\n",
      " [1.8108013]\n",
      " [2.3259077]\n",
      " [2.1356087]\n",
      " [1.3940467]\n",
      " [1.2231796]]\n",
      "90 Cost:  3.141584 \n",
      "Prediction:\n",
      " [[2.9710855]\n",
      " [3.3260117]\n",
      " [2.6375194]\n",
      " [1.810745 ]\n",
      " [2.3258414]\n",
      " [2.1355443]\n",
      " [1.3940029]\n",
      " [1.2231362]]\n",
      "91 Cost:  3.1413455 \n",
      "Prediction:\n",
      " [[2.9709969]\n",
      " [3.3259242]\n",
      " [2.6374464]\n",
      " [1.8106886]\n",
      " [2.3257747]\n",
      " [2.1354797]\n",
      " [1.3939592]\n",
      " [1.2230927]]\n",
      "92 Cost:  3.1411073 \n",
      "Prediction:\n",
      " [[2.9709082]\n",
      " [3.3258367]\n",
      " [2.6373734]\n",
      " [1.8106323]\n",
      " [2.325708 ]\n",
      " [2.1354153]\n",
      " [1.3939154]\n",
      " [1.2230492]]\n",
      "93 Cost:  3.1408691 \n",
      "Prediction:\n",
      " [[2.9708192]\n",
      " [3.3257494]\n",
      " [2.637301 ]\n",
      " [1.810576 ]\n",
      " [2.3256412]\n",
      " [2.1353507]\n",
      " [1.3938715]\n",
      " [1.2230058]]\n",
      "94 Cost:  3.140631 \n",
      "Prediction:\n",
      " [[2.9707303]\n",
      " [3.3256617]\n",
      " [2.637228 ]\n",
      " [1.8105196]\n",
      " [2.3255744]\n",
      " [2.1352863]\n",
      " [1.3938278]\n",
      " [1.2229624]]\n",
      "95 Cost:  3.1403928 \n",
      "Prediction:\n",
      " [[2.9706416]\n",
      " [3.3255744]\n",
      " [2.637155 ]\n",
      " [1.8104632]\n",
      " [2.3255079]\n",
      " [2.135222 ]\n",
      " [1.393784 ]\n",
      " [1.222919 ]]\n",
      "96 Cost:  3.1401553 \n",
      "Prediction:\n",
      " [[2.970553 ]\n",
      " [3.3254871]\n",
      " [2.637082 ]\n",
      " [1.8104069]\n",
      " [2.3254414]\n",
      " [2.1351576]\n",
      " [1.3937403]\n",
      " [1.2228755]]\n",
      "97 Cost:  3.139917 \n",
      "Prediction:\n",
      " [[2.9704642]\n",
      " [3.3253996]\n",
      " [2.6370094]\n",
      " [1.8103505]\n",
      " [2.3253746]\n",
      " [2.135093 ]\n",
      " [1.3936965]\n",
      " [1.222832 ]]\n",
      "98 Cost:  3.139679 \n",
      "Prediction:\n",
      " [[2.9703755]\n",
      " [3.3253121]\n",
      " [2.6369367]\n",
      " [1.8102943]\n",
      " [2.3253078]\n",
      " [2.1350286]\n",
      " [1.3936528]\n",
      " [1.2227886]]\n",
      "99 Cost:  3.1394413 \n",
      "Prediction:\n",
      " [[2.9702866]\n",
      " [3.3252249]\n",
      " [2.6368637]\n",
      " [1.8102379]\n",
      " [2.3252413]\n",
      " [2.1349642]\n",
      " [1.393609 ]\n",
      " [1.2227452]]\n",
      "100 Cost:  3.1392035 \n",
      "Prediction:\n",
      " [[2.9701982]\n",
      " [3.3251376]\n",
      " [2.6367912]\n",
      " [1.8101815]\n",
      " [2.3251748]\n",
      " [2.1348996]\n",
      " [1.3935652]\n",
      " [1.2227017]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def min_max_scaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "\n",
    "xy = np.array(\n",
    "    [\n",
    "        [828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "        [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "        [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "        [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "        [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "        [819, 823, 1198100, 816, 820.450012],\n",
    "        [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "        [809.51001, 816.659973, 1398100, 804.539978, 809.559998],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# very important. It does not work without it.\n",
    "xy = min_max_scaler(xy)\n",
    "print(xy)\n",
    "\n",
    "'''\n",
    "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
    " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
    " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
    " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
    " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
    " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
    " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
    " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
    "'''\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(101):\n",
    "        _, cost_val, hy_val = sess.run(\n",
    "            [train, cost, hypothesis], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
